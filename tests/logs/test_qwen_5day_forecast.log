DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9d93774b-d043-487e-8bf2-6001a712aaa3', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day forecast for 40.7128, -74.0060.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028333FD3C40>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028333FD3970>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:24 GMT'), (b'x-ratelimit-remaining-tokens', b'31909'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdazo-62bZhn-9834144a6863d6ec'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834144a6863d6ec-IAD'), (b'etag', b'W/"290-8sSC7x3rbLdKsep7K890nSTQGxU"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:24.207Z'), (b'x-api-call-start', b'2025-09-22T19:06:23.812Z'), (b'x-api-received', b'2025-09-22T19:06:23.804Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 da67d85897eed331d26551a2e5a894dc.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'zYqkmwD_cmgJuAzvkfDTGy0Ir5aIMcXBsiXFhHFbEzIzAkoyIYBD8Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:24 GMT', 'x-ratelimit-remaining-tokens': '31909', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdazo-62bZhn-9834144a6863d6ec', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834144a6863d6ec-IAD', 'etag': 'W/"290-8sSC7x3rbLdKsep7K890nSTQGxU"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:24.207Z', 'x-api-call-start': '2025-09-22T19:06:23.812Z', 'x-api-received': '2025-09-22T19:06:23.804Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 da67d85897eed331d26551a2e5a894dc.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'zYqkmwD_cmgJuAzvkfDTGy0Ir5aIMcXBsiXFhHFbEzIzAkoyIYBD8Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdazo-62bZhn-9834144a6863d6ec
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day forecast for 40.7128, -74.0060.' took 1.77s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 40.7128, 'lon': -74.006})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-65eb31f5-e820-4b56-8630-1afd7b5a0497', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Next 5 days near -33.8688, 151.2093?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334015BA0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334015630>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:30 GMT'), (b'x-ratelimit-remaining-tokens', b'32476'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdckw-66dFFu-9834146f3dde597a'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834146f3dde597a-IAD'), (b'etag', b'W/"291-O3EP5xNXQgcJwH922jro5caO1XA"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:30.168Z'), (b'x-api-call-start', b'2025-09-22T19:06:29.739Z'), (b'x-api-received', b'2025-09-22T19:06:29.728Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 4fe08c05b7ff5ae3c519e29292acc772.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'xkJFhplxJTWTxzZQRYkpxTgQVxGZ9hXVU2--ehdh21qbyKfQ7BQCrg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:30 GMT', 'x-ratelimit-remaining-tokens': '32476', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdckw-66dFFu-9834146f3dde597a', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834146f3dde597a-IAD', 'etag': 'W/"291-O3EP5xNXQgcJwH922jro5caO1XA"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:30.168Z', 'x-api-call-start': '2025-09-22T19:06:29.739Z', 'x-api-received': '2025-09-22T19:06:29.728Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 4fe08c05b7ff5ae3c519e29292acc772.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'xkJFhplxJTWTxzZQRYkpxTgQVxGZ9hXVU2--ehdh21qbyKfQ7BQCrg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdckw-66dFFu-9834146f3dde597a
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Next 5 days near -33.8688, 151.2093?' took 0.92s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': -33.8688, 'lon': 151.2093})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-bd7448b9-dc0b-4179-aaa7-e23d10b4f523', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast (5d) at -23.5505, -46.6333.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334017A30>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334017610>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:36 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdecR-66dFFu-983414962ac1c3b1'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983414962ac1c3b1-IAD'), (b'etag', b'W/"290-ykfHavaLVibDTCNkQ4OdSh4z6Yc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:36.364Z'), (b'x-api-call-start', b'2025-09-22T19:06:35.972Z'), (b'x-api-received', b'2025-09-22T19:06:35.962Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 da67d85897eed331d26551a2e5a894dc.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'DZm2SnTR3gVqb3xIL0fjZbmle_Y4FNWdUC5Xm_gT_xhlXGwGFUqiGw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:36 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdecR-66dFFu-983414962ac1c3b1', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983414962ac1c3b1-IAD', 'etag': 'W/"290-ykfHavaLVibDTCNkQ4OdSh4z6Yc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:36.364Z', 'x-api-call-start': '2025-09-22T19:06:35.972Z', 'x-api-received': '2025-09-22T19:06:35.962Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 da67d85897eed331d26551a2e5a894dc.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'DZm2SnTR3gVqb3xIL0fjZbmle_Y4FNWdUC5Xm_gT_xhlXGwGFUqiGw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdecR-66dFFu-983414962ac1c3b1
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast (5d) at -23.5505, -46.6333.' took 1.24s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': -23.5505, 'lon': -46.6333})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ec7e7495-0f00-402d-8316-64fdfea621f1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Show me 5-day outlook for 30.0444, 31.2357.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334017100>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334017130>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:42 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdgLw-66dFFu-983414bacbeec58b'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983414bacbeec58b-IAD'), (b'etag', b'W/"290-KM9sySJkb4K7BNH3uSG+cUGZjJg"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:42.780Z'), (b'x-api-call-start', b'2025-09-22T19:06:41.801Z'), (b'x-api-received', b'2025-09-22T19:06:41.792Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'2i45-_M2QFZRn8zevx9qv9gcUSMWEgTexCqp9blFR4VyptJSrGqWyw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:42 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdgLw-66dFFu-983414bacbeec58b', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983414bacbeec58b-IAD', 'etag': 'W/"290-KM9sySJkb4K7BNH3uSG+cUGZjJg"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:42.780Z', 'x-api-call-start': '2025-09-22T19:06:41.801Z', 'x-api-received': '2025-09-22T19:06:41.792Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '2i45-_M2QFZRn8zevx9qv9gcUSMWEgTexCqp9blFR4VyptJSrGqWyw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdgLw-66dFFu-983414bacbeec58b
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Show me 5-day outlook for 30.0444, 31.2357.' took 1.28s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 30.0444, 'lon': 31.2357})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-34aa9650-0107-4284-aa51-baf2164f1891', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the week ahead at 55.7558, 37.6173?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:48 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdiC6-3NKUce-983414e20f4af4b5'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983414e20f4af4b5-IAD'), (b'etag', b'W/"28f-L6xC5X1522CWtTGKZsEmCtCLuFc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:48.439Z'), (b'x-api-call-start', b'2025-09-22T19:06:48.017Z'), (b'x-api-received', b'2025-09-22T19:06:48.008Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'NnkG5XxPbt8wdG7xL0-4vmHjGc2iQE3hM56Q6B5KdxFKj1FqCCZ30A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:48 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdiC6-3NKUce-983414e20f4af4b5', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983414e20f4af4b5-IAD', 'etag': 'W/"28f-L6xC5X1522CWtTGKZsEmCtCLuFc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:48.439Z', 'x-api-call-start': '2025-09-22T19:06:48.017Z', 'x-api-received': '2025-09-22T19:06:48.008Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'NnkG5XxPbt8wdG7xL0-4vmHjGc2iQE3hM56Q6B5KdxFKj1FqCCZ30A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdiC6-3NKUce-983414e20f4af4b5
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'What's the week ahead at 55.7558, 37.6173?' took 0.78s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 55.7558, 'lon': 37.6173})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-02684f8d-507e-4231-974c-2b9e21eacfdc', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Five-day forecast around -1.2921, 36.8219.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:06:54 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdjv6-3NKUce-98341505ff5055eb'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341505ff5055eb-IAD'), (b'etag', b'W/"28f-yWUKG+tMQQ/InSi4RunOhus8cK0"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:06:54.282Z'), (b'x-api-call-start', b'2025-09-22T19:06:53.816Z'), (b'x-api-received', b'2025-09-22T19:06:53.807Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'CbLdulF_NXFDb9aKXDKgMoVxrgSUk9V1G0nDVsz1xmDwxSwKivGDjg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:06:54 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdjv6-3NKUce-98341505ff5055eb', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341505ff5055eb-IAD', 'etag': 'W/"28f-yWUKG+tMQQ/InSi4RunOhus8cK0"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:06:54.282Z', 'x-api-call-start': '2025-09-22T19:06:53.816Z', 'x-api-received': '2025-09-22T19:06:53.807Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'CbLdulF_NXFDb9aKXDKgMoVxrgSUk9V1G0nDVsz1xmDwxSwKivGDjg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdjv6-3NKUce-98341505ff5055eb
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Five-day forecast around -1.2921, 36.8219.' took 0.84s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 36.8219, 'lon': -1.2921})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-41922992-c217-4498-90d5-e54fd079eaba', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Is it cooling later this week near 64.1466, -21.9426?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:00 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdmi5-3NKUce-9834152bbecbc577'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834152bbecbc577-IAD'), (b'etag', b'W/"291-G7FRwvs+cO8ng8/VGtqXrKEbJFc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:00.298Z'), (b'x-api-call-start', b'2025-09-22T19:06:59.851Z'), (b'x-api-received', b'2025-09-22T19:06:59.839Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'onaWj9Os-3QYzdJWudZaE06StfIMk5356gdTplMuFFF7x9l8rQU4vg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:00 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdmi5-3NKUce-9834152bbecbc577', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834152bbecbc577-IAD', 'etag': 'W/"291-G7FRwvs+cO8ng8/VGtqXrKEbJFc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:00.298Z', 'x-api-call-start': '2025-09-22T19:06:59.851Z', 'x-api-received': '2025-09-22T19:06:59.839Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f080ddd5484ddefbbb5d2d08b2629a70.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'onaWj9Os-3QYzdJWudZaE06StfIMk5356gdTplMuFFF7x9l8rQU4vg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdmi5-3NKUce-9834152bbecbc577
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Is it cooling later this week near 64.1466, -21.9426?' took 1.03s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 64.1466, 'lon': -21.9426})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-22dbfef8-94d6-4c30-ae77-ce0576ee43aa', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Give 5-day hi/lo for -33.9249, 18.4241.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000283340866B0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334086290>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:06 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdoUd-66dFFu-98341550dc192ac2'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341550dc192ac2-IAD'), (b'etag', b'W/"290-1X0v5svXdZqMcCude2S93NwNY+0"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:06.197Z'), (b'x-api-call-start', b'2025-09-22T19:07:05.798Z'), (b'x-api-received', b'2025-09-22T19:07:05.786Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'vez8FwocLJkCRa9C0s-CRQ7mr53bm-HvI6hPLB9OHQUBYJixtlI1Cw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:06 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdoUd-66dFFu-98341550dc192ac2', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341550dc192ac2-IAD', 'etag': 'W/"290-1X0v5svXdZqMcCude2S93NwNY+0"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:06.197Z', 'x-api-call-start': '2025-09-22T19:07:05.798Z', 'x-api-received': '2025-09-22T19:07:05.786Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'vez8FwocLJkCRa9C0s-CRQ7mr53bm-HvI6hPLB9OHQUBYJixtlI1Cw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdoUd-66dFFu-98341550dc192ac2
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Give 5-day hi/lo for -33.9249, 18.4241.' took 0.75s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': -33.9249, 'lon': 18.4241})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-bb669bb5-58f4-4528-9bef-ab47fe36b6cf', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast next days at 35.6895, 139.6917.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:12 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdqD7-3NKUce-983415743f492f1e'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983415743f492f1e-IAD'), (b'etag', b'W/"291-lnqRWhSBLVfIp3bOOs7AxOkOnJg"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:12.078Z'), (b'x-api-call-start', b'2025-09-22T19:07:11.626Z'), (b'x-api-received', b'2025-09-22T19:07:11.615Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'koWnqMGMslaofF0Y-tTP6Me36Q9u4-p0IxD-SyHRrEq3ORLfhJ-etg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:12 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdqD7-3NKUce-983415743f492f1e', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983415743f492f1e-IAD', 'etag': 'W/"291-lnqRWhSBLVfIp3bOOs7AxOkOnJg"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:12.078Z', 'x-api-call-start': '2025-09-22T19:07:11.626Z', 'x-api-received': '2025-09-22T19:07:11.615Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'koWnqMGMslaofF0Y-tTP6Me36Q9u4-p0IxD-SyHRrEq3ORLfhJ-etg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdqD7-3NKUce-983415743f492f1e
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast next days at 35.6895, 139.6917.' took 0.91s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 35.6895, 'lon': 139.6917})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f973b291-7a64-4be7-8442-2ce28aa42ee8', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Five-day for 38.7223, -9.1393 (Lisbon).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:17 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdrx5-3NKUce-983415992ba0cb8c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983415992ba0cb8c-IAD'), (b'etag', b'W/"290-XW5NqJPfUyIJVmQZ72P4EBs+G+A"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:17.991Z'), (b'x-api-call-start', b'2025-09-22T19:07:17.482Z'), (b'x-api-received', b'2025-09-22T19:07:17.470Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'j_InqKKGpt8pOVltTpUW5-IltOqaJtSGiUaeT2fgc4PgrO94K4mCMQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:17 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdrx5-3NKUce-983415992ba0cb8c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983415992ba0cb8c-IAD', 'etag': 'W/"290-XW5NqJPfUyIJVmQZ72P4EBs+G+A"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:17.991Z', 'x-api-call-start': '2025-09-22T19:07:17.482Z', 'x-api-received': '2025-09-22T19:07:17.470Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 df12d2b385dac3f516d1788990ebf43a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'j_InqKKGpt8pOVltTpUW5-IltOqaJtSGiUaeT2fgc4PgrO94K4mCMQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdrx5-3NKUce-983415992ba0cb8c
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Five-day for 38.7223, -9.1393 (Lisbon).' took 0.95s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': 38.7223, 'lon': -9.1393})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-78c61c48-21fa-4154-84ff-a4760b498d5c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day forecast 10001, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028334084A00>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000283340842E0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:23 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdtmF-3NKUce-983415befbeb255f'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983415befbeb255f-IAD'), (b'etag', b'W/"29a-xDy+hn/auMwwVNDPn2UYNcsCZfY"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:23.994Z'), (b'x-api-call-start', b'2025-09-22T19:07:23.582Z'), (b'x-api-received', b'2025-09-22T19:07:23.570Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 881a5a546bfcb1f1b6d589576d5ee9f6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'6kohSBIsjaBIJXyXFoXzXQ_CgGqX5OBtpwMBfcTWJV14LiOKIWIB-Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:23 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdtmF-3NKUce-983415befbeb255f', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983415befbeb255f-IAD', 'etag': 'W/"29a-xDy+hn/auMwwVNDPn2UYNcsCZfY"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:23.994Z', 'x-api-call-start': '2025-09-22T19:07:23.582Z', 'x-api-received': '2025-09-22T19:07:23.570Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 881a5a546bfcb1f1b6d589576d5ee9f6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '6kohSBIsjaBIJXyXFoXzXQ_CgGqX5OBtpwMBfcTWJV14LiOKIWIB-Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdtmF-3NKUce-983415befbeb255f
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day forecast 10001, US.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '10001', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-4004f8db-01f4-4f8b-be89-584499982a02', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast for 90210, US next 5 days.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833506DD20>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833506D900>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:29 GMT'), (b'x-ratelimit-remaining-tokens', b'31020'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdvSk-62bZhn-983415e32ef8082b'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983415e32ef8082b-IAD'), (b'etag', b'W/"299-XBMwe4RprGW42zeFcujLGmEcSJE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:29.618Z'), (b'x-api-call-start', b'2025-09-22T19:07:29.237Z'), (b'x-api-received', b'2025-09-22T19:07:29.226Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'FwcqEGwlgI6Z-VTpD_hXWeBI1P5at_NJyqvO0hbiQwwck7PM26Tbcw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:29 GMT', 'x-ratelimit-remaining-tokens': '31020', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdvSk-62bZhn-983415e32ef8082b', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983415e32ef8082b-IAD', 'etag': 'W/"299-XBMwe4RprGW42zeFcujLGmEcSJE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:29.618Z', 'x-api-call-start': '2025-09-22T19:07:29.237Z', 'x-api-received': '2025-09-22T19:07:29.226Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'FwcqEGwlgI6Z-VTpD_hXWeBI1P5at_NJyqvO0hbiQwwck7PM26Tbcw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdvSk-62bZhn-983415e32ef8082b
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast for 90210, US next 5 days.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '90210', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9e5db1c7-50d2-46d5-ab0f-351c9b1b4524', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather outlook 60614, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:07:35 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHdxAW-62bZhn-98341607593a289e'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341607593a289e-IAD'), (b'etag', b'W/"299-O8WwzAq5Z718M1ABWC9NJbECPEc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:07:35.483Z'), (b'x-api-call-start', b'2025-09-22T19:07:35.019Z'), (b'x-api-received', b'2025-09-22T19:07:35.011Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'bGzbG92lcZN07O-j0dv5xjirLjlb3U2xPoIv0BZoo8VSx1OVSId3ZA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:07:35 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHdxAW-62bZhn-98341607593a289e', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341607593a289e-IAD', 'etag': 'W/"299-O8WwzAq5Z718M1ABWC9NJbECPEc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:07:35.483Z', 'x-api-call-start': '2025-09-22T19:07:35.019Z', 'x-api-received': '2025-09-22T19:07:35.011Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'bGzbG92lcZN07O-j0dv5xjirLjlb3U2xPoIv0BZoo8VSx1OVSId3ZA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHdxAW-62bZhn-98341607593a289e
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Weather outlook 60614, US.' took 0.75s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '60614', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0d1f29b9-57d2-4de5-a57c-6e37bb776748', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day for 10115, DE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AA3C70>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017C1816F840> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AA39A0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:44:05 GMT'), (b'x-ratelimit-remaining-tokens', b'31489'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJU5bv-62bZhn-9834fb496c0f0624'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834fb496c0f0624-IAD'), (b'etag', b'W/"299-HeN9FfPIaV/dAIopjDo4bqPuPXk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:44:05.850Z'), (b'x-api-call-start', b'2025-09-22T21:44:05.417Z'), (b'x-api-received', b'2025-09-22T21:44:05.409Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 fee1af928fb542120a907076855ee8f0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'mq3-0mv7C_gYP50nbpKuXAl7Fiviv4iUPbZ2J1Qow1riOdCWfsbj_g==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:44:05 GMT', 'x-ratelimit-remaining-tokens': '31489', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJU5bv-62bZhn-9834fb496c0f0624', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834fb496c0f0624-IAD', 'etag': 'W/"299-HeN9FfPIaV/dAIopjDo4bqPuPXk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:44:05.850Z', 'x-api-call-start': '2025-09-22T21:44:05.417Z', 'x-api-received': '2025-09-22T21:44:05.409Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 fee1af928fb542120a907076855ee8f0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'mq3-0mv7C_gYP50nbpKuXAl7Fiviv4iUPbZ2J1Qow1riOdCWfsbj_g=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJU5bv-62bZhn-9834fb496c0f0624
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day for 10115, DE.' took 1.33s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '10115', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-13b86eed-183b-427e-95db-24bad915dc96', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Next five days SW1A 1AA, GB.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AE5BD0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017C1816F840> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AE5660>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:44:11 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJU7M6-66dFFu-9834fb6dcbf2d600'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834fb6dcbf2d600-IAD'), (b'etag', b'W/"29c-uQ+/Kz0e1qWt3E1AuEA+itpr4o8"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:44:11.722Z'), (b'x-api-call-start', b'2025-09-22T21:44:11.291Z'), (b'x-api-received', b'2025-09-22T21:44:11.278Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 163cab6be16ba1fb5ee75dd6beeee0e2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'6bENly4eUP55JabqxTtEVlMGfmcl3y1nVH5QvclU24-RyrTJXTtBBQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:44:11 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJU7M6-66dFFu-9834fb6dcbf2d600', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834fb6dcbf2d600-IAD', 'etag': 'W/"29c-uQ+/Kz0e1qWt3E1AuEA+itpr4o8"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:44:11.722Z', 'x-api-call-start': '2025-09-22T21:44:11.291Z', 'x-api-received': '2025-09-22T21:44:11.278Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 163cab6be16ba1fb5ee75dd6beeee0e2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': '6bENly4eUP55JabqxTtEVlMGfmcl3y1nVH5QvclU24-RyrTJXTtBBQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJU7M6-66dFFu-9834fb6dcbf2d600
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Next five days SW1A 1AA, GB.' took 0.84s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': 'SW1A 1AA', 'country_code': 'GB'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a90e0484-e17f-40c3-9eb7-d89c9e256ae5', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast 75001, FR.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AE7A60>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017C1816F840> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19AE7640>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:44:17 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJU94h-66dFFu-9834fb923905d962'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834fb923905d962-IAD'), (b'etag', b'W/"299-SixrJu7ZYLA/9EdTG6hf5jB2uE4"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:44:17.432Z'), (b'x-api-call-start', b'2025-09-22T21:44:17.065Z'), (b'x-api-received', b'2025-09-22T21:44:17.055Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 fee1af928fb542120a907076855ee8f0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'lG2kZ-AnANnfJTPdEymFa1dtIr8ck7PpDiYTdSJY3PWozgn7WRxRGg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:44:17 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJU94h-66dFFu-9834fb923905d962', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834fb923905d962-IAD', 'etag': 'W/"299-SixrJu7ZYLA/9EdTG6hf5jB2uE4"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:44:17.432Z', 'x-api-call-start': '2025-09-22T21:44:17.065Z', 'x-api-received': '2025-09-22T21:44:17.055Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 fee1af928fb542120a907076855ee8f0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'lG2kZ-AnANnfJTPdEymFa1dtIr8ck7PpDiYTdSJY3PWozgn7WRxRGg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJU94h-66dFFu-9834fb923905d962
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast 75001, FR.' took 0.69s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '75001', 'country_code': 'FR'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ca9ed613-d018-40f1-91cb-313085294f97', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day for 1250-096, PT.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19B45810>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017C1816F840> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19B453F0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:44:23 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'0'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJUAmA-62bZhn-9834fbb5ee5705fc'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834fbb5ee5705fc-IAD'), (b'etag', b'W/"29c-LCSxjPwQ4sYQihMY++MdqLy9tzw"'), (b'retry-after', b'0'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:44:23.150Z'), (b'x-api-call-start', b'2025-09-22T21:44:22.773Z'), (b'x-api-received', b'2025-09-22T21:44:22.765Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'191'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 163cab6be16ba1fb5ee75dd6beeee0e2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'qg_M1ooY-VM4BwOhIAqquOlhCaIiCGPWdJMPuIv6bEY2sNBV8RhEvA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:44:23 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '0', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJUAmA-62bZhn-9834fbb5ee5705fc', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834fbb5ee5705fc-IAD', 'etag': 'W/"29c-LCSxjPwQ4sYQihMY++MdqLy9tzw"', 'retry-after': '0', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:44:23.150Z', 'x-api-call-start': '2025-09-22T21:44:22.773Z', 'x-api-received': '2025-09-22T21:44:22.765Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '191', 'x-cache': 'Miss from cloudfront', 'via': '1.1 163cab6be16ba1fb5ee75dd6beeee0e2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'qg_M1ooY-VM4BwOhIAqquOlhCaIiCGPWdJMPuIv6bEY2sNBV8RhEvA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJUAmA-62bZhn-9834fbb5ee5705fc
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day for 1250-096, PT.' took 0.73s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '1250-096', 'country_code': 'PT'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0517561e-b4f4-45a3-aa50-d01f132ecbd1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast for 2000, AU.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19B47580>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000017C1816F840> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017C19B47160>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:44:29 GMT'), (b'x-ratelimit-remaining-tokens', b'28262'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJUCU9-62bZhn-9834fbd9be16c975'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834fbd9be16c975-IAD'), (b'etag', b'W/"2ab-oSTsF3OSWQ2B5+GRLrNHv+VUark"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:44:29.076Z'), (b'x-api-call-start', b'2025-09-22T21:44:28.517Z'), (b'x-api-received', b'2025-09-22T21:44:28.507Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'196'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 cb3394cad3f414f33c4f30965c750226.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'BxJHP81GYKGGqlBOGQWh8FjKCU7HCdDx2gQNIe7EkEEvkwbfCONiJQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:44:29 GMT', 'x-ratelimit-remaining-tokens': '28262', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJUCU9-62bZhn-9834fbd9be16c975', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834fbd9be16c975-IAD', 'etag': 'W/"2ab-oSTsF3OSWQ2B5+GRLrNHv+VUark"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:44:29.076Z', 'x-api-call-start': '2025-09-22T21:44:28.517Z', 'x-api-received': '2025-09-22T21:44:28.507Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '196', 'x-cache': 'Miss from cloudfront', 'via': '1.1 cb3394cad3f414f33c4f30965c750226.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'BxJHP81GYKGGqlBOGQWh8FjKCU7HCdDx2gQNIe7EkEEvkwbfCONiJQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJUCU9-62bZhn-9834fbd9be16c975
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast for 2000, AU.' took 0.92s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'lat': -33.8688, 'lon': 151.2093, 'country_code': 'AU'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-8474a436-1e4d-46ed-bbaf-044b7e6555e5', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day outlook 01000-000, BR.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:07 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHe7bP-62bZhn-983416cd4b01b964'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983416cd4b01b964-IAD'), (b'etag', b'W/"29e-hwv4g1EJoF+HriGG12JGGOJMIdc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:07.224Z'), (b'x-api-call-start', b'2025-09-22T19:08:06.738Z'), (b'x-api-received', b'2025-09-22T19:08:06.731Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 8aadc8635b9ead1f8a0c393f17634d32.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'8CQYa5Q9I940ABWSXOUTulO9hxuJ5in_B4Dq801aLjPQry42ogG-tg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:07 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHe7bP-62bZhn-983416cd4b01b964', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983416cd4b01b964-IAD', 'etag': 'W/"29e-hwv4g1EJoF+HriGG12JGGOJMIdc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:07.224Z', 'x-api-call-start': '2025-09-22T19:08:06.738Z', 'x-api-received': '2025-09-22T19:08:06.731Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 8aadc8635b9ead1f8a0c393f17634d32.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '8CQYa5Q9I940ABWSXOUTulO9hxuJ5in_B4Dq801aLjPQry42ogG-tg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHe7bP-62bZhn-983416cd4b01b964
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day outlook 01000-000, BR.' took 1.03s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '01000-000', 'country_code': 'BR'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c6f3a4aa-5c1a-44ea-8990-0afc6d548d33', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Next 5 days 110001, IN.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:13 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHe9SE-3NKUce-983416f2fe055794'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983416f2fe055794-IAD'), (b'etag', b'W/"29a-NteIHYaeGyLivvHTdP38S66z+4I"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:13.392Z'), (b'x-api-call-start', b'2025-09-22T19:08:12.937Z'), (b'x-api-received', b'2025-09-22T19:08:12.927Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 8aadc8635b9ead1f8a0c393f17634d32.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'r1ldccHe89ajDyy00U25OhJL0nxNh1bWyulMA9G_mkEGVhkcMYMfAg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:13 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHe9SE-3NKUce-983416f2fe055794', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983416f2fe055794-IAD', 'etag': 'W/"29a-NteIHYaeGyLivvHTdP38S66z+4I"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:13.392Z', 'x-api-call-start': '2025-09-22T19:08:12.937Z', 'x-api-received': '2025-09-22T19:08:12.927Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 8aadc8635b9ead1f8a0c393f17634d32.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'r1ldccHe89ajDyy00U25OhJL0nxNh1bWyulMA9G_mkEGVhkcMYMfAg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHe9SE-3NKUce-983416f2fe055794
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Next 5 days 110001, IN.' took 0.81s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'zip': '110001', 'country_code': 'IN'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2a72cd96-e6cd-4698-ac0b-4a84fb1df984', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Five-day forecast Kyoto, JP.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028335114A90>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028335114670>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:19 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeBDC-3NKUce-98341717af7c07fb'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341717af7c07fb-IAD'), (b'etag', b'W/"29a-jAhM1u07qkUQI8uCEGXH9LLZjjg"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:19.379Z'), (b'x-api-call-start', b'2025-09-22T19:08:18.910Z'), (b'x-api-received', b'2025-09-22T19:08:18.899Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'_CD7dt-aUGnMuGZbzdKdB5KnBVq9sOzZ2a_C_Y3o5gmnKDRQ8irwQQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:19 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeBDC-3NKUce-98341717af7c07fb', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341717af7c07fb-IAD', 'etag': 'W/"29a-jAhM1u07qkUQI8uCEGXH9LLZjjg"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:19.379Z', 'x-api-call-start': '2025-09-22T19:08:18.910Z', 'x-api-received': '2025-09-22T19:08:18.899Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '_CD7dt-aUGnMuGZbzdKdB5KnBVq9sOzZ2a_C_Y3o5gmnKDRQ8irwQQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeBDC-3NKUce-98341717af7c07fb
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Five-day forecast Kyoto, JP.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Kyoto', 'country_code': 'JP'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c248bbac-3d78-4438-b505-30b4f5608b45', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the 5-day in Toronto, CA?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:24 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeCrE-66dFFu-9834173bcc77dda5'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834173bcc77dda5-IAD'), (b'etag', b'W/"2b3-O3FU/ugZB5QRbgO+Hd4ssElD/MQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:24.905Z'), (b'x-api-call-start', b'2025-09-22T19:08:24.422Z'), (b'x-api-received', b'2025-09-22T19:08:24.411Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'5ntRSxaeg7Twbb-AGq6kYSgIbWG4Fh8KNdFdXDAdpGbyKRdv5qHR8A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:24 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeCrE-66dFFu-9834173bcc77dda5', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834173bcc77dda5-IAD', 'etag': 'W/"2b3-O3FU/ugZB5QRbgO+Hd4ssElD/MQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:24.905Z', 'x-api-call-start': '2025-09-22T19:08:24.422Z', 'x-api-received': '2025-09-22T19:08:24.411Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '5ntRSxaeg7Twbb-AGq6kYSgIbWG4Fh8KNdFdXDAdpGbyKRdv5qHR8A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeCrE-66dFFu-9834173bcc77dda5
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'What's the 5-day in Toronto, CA?' took 0.92s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Toronto', 'state_code': 'CA', 'units': 'standart'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-db22866e-897c-4370-9101-069b28ae5fca', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day forecast Nairobi.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:30 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeEbA-66dFFu-98341760ceb7d6df'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341760ceb7d6df-IAD'), (b'etag', b'W/"282-4ADUGsOUvFr58uBhpTtZP6YvISs"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:30.574Z'), (b'x-api-call-start', b'2025-09-22T19:08:30.275Z'), (b'x-api-received', b'2025-09-22T19:08:30.265Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'hYQP3AZaDtO2ZlGZt5KmSz2CnbqgfdlK3HSbwKRRcus0tod9ix8Hww==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:30 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeEbA-66dFFu-98341760ceb7d6df', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341760ceb7d6df-IAD', 'etag': 'W/"282-4ADUGsOUvFr58uBhpTtZP6YvISs"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:30.574Z', 'x-api-call-start': '2025-09-22T19:08:30.275Z', 'x-api-received': '2025-09-22T19:08:30.265Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'hYQP3AZaDtO2ZlGZt5KmSz2CnbqgfdlK3HSbwKRRcus0tod9ix8Hww=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeEbA-66dFFu-98341760ceb7d6df
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day forecast Nairobi.' took 0.63s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Nairobi'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a008b68c-4a94-4181-97de-3f722ac5c590', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Week ahead in Auckland, NZ.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028335115F90>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000283351171C0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:36 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeGJD-66dFFu-983417849f0f879a'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983417849f0f879a-IAD'), (b'etag', b'W/"2b4-FMlwNNRM/JlIn7L+1W8QR/FFAj8"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:36.477Z'), (b'x-api-call-start', b'2025-09-22T19:08:36.020Z'), (b'x-api-received', b'2025-09-22T19:08:36.010Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'JJVC2L05nbNSGVEeYBC_ADcEoyqKpvedAeawitJNmz8vQ1W7EwvPmA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:36 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeGJD-66dFFu-983417849f0f879a', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983417849f0f879a-IAD', 'etag': 'W/"2b4-FMlwNNRM/JlIn7L+1W8QR/FFAj8"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:36.477Z', 'x-api-call-start': '2025-09-22T19:08:36.020Z', 'x-api-received': '2025-09-22T19:08:36.010Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e0e00cad5101fc9c4314eb9d81c18aca.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'JJVC2L05nbNSGVEeYBC_ADcEoyqKpvedAeawitJNmz8vQ1W7EwvPmA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeGJD-66dFFu-983417849f0f879a
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Week ahead in Auckland, NZ.' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Auckland', 'country_code': 'NZ', 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3334704e-4cbe-4ec4-9e32-0f35fd9184d7', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day for Reykjavik, IS (typo earlier).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512CE80>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512CA60>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:42 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeJCn-3NKUce-983417a97a684e63'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983417a97a684e63-IAD'), (b'etag', b'W/"29d-H/Uc0BnifC6uPaH+hojn9P2qP9s"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:42.993Z'), (b'x-api-call-start', b'2025-09-22T19:08:42.434Z'), (b'x-api-received', b'2025-09-22T19:08:42.423Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'198'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'3JwZ6r30D7PiYdMORM-MotshUk33O6QUqKjqzIt8DCZsQZP7krBvtw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:42 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeJCn-3NKUce-983417a97a684e63', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983417a97a684e63-IAD', 'etag': 'W/"29d-H/Uc0BnifC6uPaH+hojn9P2qP9s"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:42.993Z', 'x-api-call-start': '2025-09-22T19:08:42.434Z', 'x-api-received': '2025-09-22T19:08:42.423Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '198', 'x-cache': 'Miss from cloudfront', 'via': '1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '3JwZ6r30D7PiYdMORM-MotshUk33O6QUqKjqzIt8DCZsQZP7krBvtw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeJCn-3NKUce-983417a97a684e63
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day for Reykjavik, IS (typo earlier).' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Reykjavik', 'country_code': 'IS'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-10534026-4f55-480e-ad8c-302dcc7053a6', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Forecast 5 days Lima, PE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512EBF0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512E7D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:48 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeKpK-66dFFu-983417ceabc7d657'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983417ceabc7d657-IAD'), (b'etag', b'W/"29a-w9CtbaoK2EVuRgHpa8bRGT7dj2Y"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:48.284Z'), (b'x-api-call-start', b'2025-09-22T19:08:47.858Z'), (b'x-api-received', b'2025-09-22T19:08:47.849Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b5825d3f79124e6f8419a96c48f75e2a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'grtrXEpBi_bEhvWMELc0sL42DSOYDE0Ul9cW8M7JVEBGIYYtptujUw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:48 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeKpK-66dFFu-983417ceabc7d657', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983417ceabc7d657-IAD', 'etag': 'W/"29a-w9CtbaoK2EVuRgHpa8bRGT7dj2Y"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:48.284Z', 'x-api-call-start': '2025-09-22T19:08:47.858Z', 'x-api-received': '2025-09-22T19:08:47.849Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b5825d3f79124e6f8419a96c48f75e2a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'grtrXEpBi_bEhvWMELc0sL42DSOYDE0Ul9cW8M7JVEBGIYYtptujUw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeKpK-66dFFu-983417ceabc7d657
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Forecast 5 days Lima, PE.' took 0.83s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Lima', 'country_code': 'PE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-172bde23-025b-425f-9467-be20b7937f2d', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Next 5 days Johannesburg, ZA.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833513C9A0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833513C580>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:08:54 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeMZ8-66dFFu-983417f33a1dda52'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983417f33a1dda52-IAD'), (b'etag', b'W/"2ae-8Tu/8f6j5UGhR2iIn2gcu+9vCyM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:08:54.123Z'), (b'x-api-call-start', b'2025-09-22T19:08:53.705Z'), (b'x-api-received', b'2025-09-22T19:08:53.695Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 881a5a546bfcb1f1b6d589576d5ee9f6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'AM_bcQ_DAUjWXxFDZeCvLnzknPhM3Ga3f7ptTce3-FwJuBSgjlIN_A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:08:54 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeMZ8-66dFFu-983417f33a1dda52', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983417f33a1dda52-IAD', 'etag': 'W/"2ae-8Tu/8f6j5UGhR2iIn2gcu+9vCyM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:08:54.123Z', 'x-api-call-start': '2025-09-22T19:08:53.705Z', 'x-api-received': '2025-09-22T19:08:53.695Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 881a5a546bfcb1f1b6d589576d5ee9f6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'AM_bcQ_DAUjWXxFDZeCvLnzknPhM3Ga3f7ptTce3-FwJuBSgjlIN_A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeMZ8-66dFFu-983417f33a1dda52
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Next 5 days Johannesburg, ZA.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Johannesburg', 'country_code': 'ZA'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fa83e1c5-6904-444d-b053-b1947764c207', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Munich, DE 5-day outlook.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512ED70>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833512F9A0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:09:00 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHePJ2-66dFFu-983418179caf8791'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983418179caf8791-IAD'), (b'etag', b'W/"29b-IJVNPedQtcpAn0cSPOs8QYXCUxs"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:09:00.011Z'), (b'x-api-call-start', b'2025-09-22T19:08:59.557Z'), (b'x-api-received', b'2025-09-22T19:08:59.547Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ce4d5cfcd9ad826e9d9eb4efddff685c.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'0kp21uDenhr5OPWPGtITZojZalx_LA8Yu1nfsQ1kjM54Y6DB16jOqw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:09:00 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHePJ2-66dFFu-983418179caf8791', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983418179caf8791-IAD', 'etag': 'W/"29b-IJVNPedQtcpAn0cSPOs8QYXCUxs"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:09:00.011Z', 'x-api-call-start': '2025-09-22T19:08:59.557Z', 'x-api-received': '2025-09-22T19:08:59.547Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ce4d5cfcd9ad826e9d9eb4efddff685c.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '0kp21uDenhr5OPWPGtITZojZalx_LA8Yu1nfsQ1kjM54Y6DB16jOqw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHePJ2-66dFFu-983418179caf8791
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'Munich, DE 5-day outlook.' took 0.83s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Munich', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7e30d099-0878-47a0-9e55-1291f542d3d4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'San Francisco, US-CA 5-day forecast.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:09:05 GMT'), (b'x-ratelimit-remaining-tokens', b'30683'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeRLR-3NKUce-9834183bac9a084b'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9834183bac9a084b-IAD'), (b'etag', b'W/"2bb-NXQ8qEfmF6ZsRa3oAevsVMUVqVk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:09:06.821Z'), (b'x-api-call-start', b'2025-09-22T19:09:06.425Z'), (b'x-api-received', b'2025-09-22T19:09:06.414Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ce4d5cfcd9ad826e9d9eb4efddff685c.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'WnbM0JpgjZ8Ic6yp-SHxkPt6x2H9hf8gD7FyKitL2IcYW49f7VyYAQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:09:05 GMT', 'x-ratelimit-remaining-tokens': '30683', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeRLR-3NKUce-9834183bac9a084b', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9834183bac9a084b-IAD', 'etag': 'W/"2bb-NXQ8qEfmF6ZsRa3oAevsVMUVqVk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:09:06.821Z', 'x-api-call-start': '2025-09-22T19:09:06.425Z', 'x-api-received': '2025-09-22T19:09:06.414Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ce4d5cfcd9ad826e9d9eb4efddff685c.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'WnbM0JpgjZ8Ic6yp-SHxkPt6x2H9hf8gD7FyKitL2IcYW49f7VyYAQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeRLR-3NKUce-9834183bac9a084b
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation 'San Francisco, US-CA 5-day forecast.' took 0.94s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'San Francisco', 'state_code': 'CA', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-815303b8-0cf8-42c2-9691-8638ff574e0f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': '5-day for Porto, PT.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833513E0E0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028333683D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002833513C8E0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:09:11 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHeSqR-66dFFu-98341861480d5a10'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341861480d5a10-IAD'), (b'etag', b'W/"29a-knkd3OQWwaDc1Z6VmUOmd2QChM8"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:09:11.951Z'), (b'x-api-call-start', b'2025-09-22T19:09:11.470Z'), (b'x-api-received', b'2025-09-22T19:09:11.460Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'AR_Ip8_zqf0JcNwgonAM_63EzX1DJ9-sWZQLzMJKDfZRxx8q_ci_Fg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:09:11 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHeSqR-66dFFu-98341861480d5a10', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341861480d5a10-IAD', 'etag': 'W/"29a-knkd3OQWwaDc1Z6VmUOmd2QChM8"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:09:11.951Z', 'x-api-call-start': '2025-09-22T19:09:11.470Z', 'x-api-received': '2025-09-22T19:09:11.460Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'AR_Ip8_zqf0JcNwgonAM_63EzX1DJ9-sWZQLzMJKDfZRxx8q_ci_Fg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHeSqR-66dFFu-98341861480d5a10
DEBUG    test_performance:test_performance.py:305 5 day forecast conversation '5-day for Porto, PT.' took 1.02s with response: 
LLMResponse(type='function_call', content=None, function='get_forecast', module='meteorology', arguments={'city': 'Porto', 'country_code': 'PT'})


