DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-018b9d86-9803-4311-bbfa-981b756e1e77', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current air quality at 40.7128, -74.0060?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D86D3BE0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D86D3910>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:13 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHf4rc-62bZhn-98341b577a725a39'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341b577a725a39-IAD'), (b'etag', b'W/"294-Yh+Ez7s42s0XpMkUpuY/5xqTDN0"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:13.070Z'), (b'x-api-call-start', b'2025-09-22T19:11:12.644Z'), (b'x-api-received', b'2025-09-22T19:11:12.633Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f3fde10f0f66dfa1e61fd07129f1aa54.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'd2sFQUVnZZA2gV98FrbPDRBNnL24l5Br3n1AgBkMy9pkwBg4wyrSeQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:13 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHf4rc-62bZhn-98341b577a725a39', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341b577a725a39-IAD', 'etag': 'W/"294-Yh+Ez7s42s0XpMkUpuY/5xqTDN0"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:13.070Z', 'x-api-call-start': '2025-09-22T19:11:12.644Z', 'x-api-received': '2025-09-22T19:11:12.633Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f3fde10f0f66dfa1e61fd07129f1aa54.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'd2sFQUVnZZA2gV98FrbPDRBNnL24l5Br3n1AgBkMy9pkwBg4wyrSeQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHf4rc-62bZhn-98341b577a725a39
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Current air quality at 40.7128, -74.0060?' took 1.79s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 40.7128, 'lon': -74.006})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6ca36a02-a5f7-4277-8cb2-94cf27ce5a06', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI near -33.8688, 151.2093 right now.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D8715B40>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D87155D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:19 GMT'), (b'x-ratelimit-remaining-tokens', b'26256'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHf6n9-3NKUce-98341b7d8be7c956'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341b7d8be7c956-IAD'), (b'etag', b'W/"2a4-zu2cHwPeOoEZLN+OJG78h5Xh124"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:19.711Z'), (b'x-api-call-start', b'2025-09-22T19:11:19.113Z'), (b'x-api-received', b'2025-09-22T19:11:19.102Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'tFG8o9x6LkqBEvk7WuFzwee8gLvZ83HmADh_7s34KJpuCzDorv5UdA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:19 GMT', 'x-ratelimit-remaining-tokens': '26256', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHf6n9-3NKUce-98341b7d8be7c956', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341b7d8be7c956-IAD', 'etag': 'W/"2a4-zu2cHwPeOoEZLN+OJG78h5Xh124"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:19.711Z', 'x-api-call-start': '2025-09-22T19:11:19.113Z', 'x-api-received': '2025-09-22T19:11:19.102Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'tFG8o9x6LkqBEvk7WuFzwee8gLvZ83HmADh_7s34KJpuCzDorv5UdA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHf6n9-3NKUce-98341b7d8be7c956
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI near -33.8688, 151.2093 right now.' took 1.24s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': -33.8688, 'lon': 151.2093})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-cf34d546-f56e-4aa3-9ce0-782c81356c85', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's PM2.5 at -23.5505, -46.6333?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:25 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHf8SZ-66dFFu-98341ba2c8947048'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341ba2c8947048-IAD'), (b'etag', b'W/"296-SJYqd6vGFAL2yG0o+FF++LlUpHw"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:25.230Z'), (b'x-api-call-start', b'2025-09-22T19:11:24.706Z'), (b'x-api-received', b'2025-09-22T19:11:24.695Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'diDz11XWeCNLO0ngvyrHp5FvtM7nq7uXcz9Eiz2ffX9JUiptwTxtJg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:25 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHf8SZ-66dFFu-98341ba2c8947048', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341ba2c8947048-IAD', 'etag': 'W/"296-SJYqd6vGFAL2yG0o+FF++LlUpHw"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:25.230Z', 'x-api-call-start': '2025-09-22T19:11:24.706Z', 'x-api-received': '2025-09-22T19:11:24.695Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'diDz11XWeCNLO0ngvyrHp5FvtM7nq7uXcz9Eiz2ffX9JUiptwTxtJg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHf8SZ-66dFFu-98341ba2c8947048
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'What's PM2.5 at -23.5505, -46.6333?' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': -23.5505, 'lon': -46.6333})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-898e2233-874e-4b52-8f61-1221d5cb1d04', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air pollution for 30.0444, 31.2357.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D8717B80>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D8717A00>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:31 GMT'), (b'x-ratelimit-remaining-tokens', b'27642'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfAEB-62bZhn-98341bc869bfd6d0'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341bc869bfd6d0-IAD'), (b'etag', b'W/"294-7cAloKwhIHBXOB1S9oyHeiDIFyA"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:31.098Z'), (b'x-api-call-start', b'2025-09-22T19:11:30.714Z'), (b'x-api-received', b'2025-09-22T19:11:30.704Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'198'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'sUaz4oBiwoRN0LC9GKT1AnaVQgADoGw4dFGkCp3MBkT7dkHdls6P5g==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:31 GMT', 'x-ratelimit-remaining-tokens': '27642', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfAEB-62bZhn-98341bc869bfd6d0', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341bc869bfd6d0-IAD', 'etag': 'W/"294-7cAloKwhIHBXOB1S9oyHeiDIFyA"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:31.098Z', 'x-api-call-start': '2025-09-22T19:11:30.714Z', 'x-api-received': '2025-09-22T19:11:30.704Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '198', 'x-cache': 'Miss from cloudfront', 'via': '1.1 52923a8d354a8b3a1b839b39ec3a8ae6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'sUaz4oBiwoRN0LC9GKT1AnaVQgADoGw4dFGkCp3MBkT7dkHdls6P5g=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfAEB-62bZhn-98341bc869bfd6d0
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air pollution for 30.0444, 31.2357.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 30.0444, 'lon': 31.2357})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7518462f-2bf6-4c02-8627-5400a7aedae2', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI around 55.7558, 37.6173 (Moscow).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D87718D0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D87714B0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:37 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfBxK-3NKUce-98341becdb80dd0c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341becdb80dd0c-IAD'), (b'etag', b'W/"295-0LEJu9X+nXp7RjSE60YhLEiIoQQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:37.049Z'), (b'x-api-call-start', b'2025-09-22T19:11:36.522Z'), (b'x-api-received', b'2025-09-22T19:11:36.512Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 8692422a46e533f30b9ae6995938ab04.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'UmS_FNU-eDZokWo2AkiRmar1IZKlJNNJv22ozA8cdnLqIyVWawUmPQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:37 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfBxK-3NKUce-98341becdb80dd0c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341becdb80dd0c-IAD', 'etag': 'W/"295-0LEJu9X+nXp7RjSE60YhLEiIoQQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:37.049Z', 'x-api-call-start': '2025-09-22T19:11:36.522Z', 'x-api-received': '2025-09-22T19:11:36.512Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 8692422a46e533f30b9ae6995938ab04.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'UmS_FNU-eDZokWo2AkiRmar1IZKlJNNJv22ozA8cdnLqIyVWawUmPQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfBxK-3NKUce-98341becdb80dd0c
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI around 55.7558, 37.6173 (Moscow).' took 0.96s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 55.7558, 'lon': 37.6173})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-6c9e219d-1cd0-407e-ace3-485da6adc986', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current AQI for -1.2921, 36.8219.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D8773640>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D8773220>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:43 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfDoo-3NKUce-98341c121e990825'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341c121e990825-IAD'), (b'etag', b'W/"294-4uAmAPWjpJmXu9JMsrV3Fb49pFU"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:43.238Z'), (b'x-api-call-start', b'2025-09-22T19:11:42.768Z'), (b'x-api-received', b'2025-09-22T19:11:42.748Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 93737c1ac104ace3048dc3a42672dca2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'C3KSck9KAluy32oQhC7f89XqKK3rCNJRKAm3tqDa67-84LYnzqFgsQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:43 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfDoo-3NKUce-98341c121e990825', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341c121e990825-IAD', 'etag': 'W/"294-4uAmAPWjpJmXu9JMsrV3Fb49pFU"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:43.238Z', 'x-api-call-start': '2025-09-22T19:11:42.768Z', 'x-api-received': '2025-09-22T19:11:42.748Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 93737c1ac104ace3048dc3a42672dca2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'C3KSck9KAluy32oQhC7f89XqKK3rCNJRKAm3tqDa67-84LYnzqFgsQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfDoo-3NKUce-98341c121e990825
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Current AQI for -1.2921, 36.8219.' took 0.83s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': -1.2921, 'lon': 36.8219})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a79e4ef8-c070-416d-8bf9-ab46b28a25ea', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Is air clean near 64.1466, -21.9426?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D878D420>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D878D240>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:48 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfFRP-3NKUce-98341c369a8d7f1b'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341c369a8d7f1b-IAD'), (b'etag', b'W/"295-FvYWqTbviKPqC7ZIScJKG00d7jM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:48.647Z'), (b'x-api-call-start', b'2025-09-22T19:11:48.184Z'), (b'x-api-received', b'2025-09-22T19:11:48.174Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'r09P5mXSzojKxFFTMOk6befBf9oxa7ULATZeIA-l_WtEN8TTMj7aDg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:48 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfFRP-3NKUce-98341c369a8d7f1b', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341c369a8d7f1b-IAD', 'etag': 'W/"295-FvYWqTbviKPqC7ZIScJKG00d7jM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:48.647Z', 'x-api-call-start': '2025-09-22T19:11:48.184Z', 'x-api-received': '2025-09-22T19:11:48.174Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'r09P5mXSzojKxFFTMOk6befBf9oxa7ULATZeIA-l_WtEN8TTMj7aDg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfFRP-3NKUce-98341c369a8d7f1b
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Is air clean near 64.1466, -21.9426?' took 0.81s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 64.1466, 'lon': -21.9426})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-8d0c30bd-4cc8-4317-8177-43e3dc880c23', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Pollution stats at -33.9249, 18.4241.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:11:54 GMT'), (b'x-ratelimit-remaining-tokens', b'29165'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfHAQ-62bZhn-98341c5a5c6fd962'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341c5a5c6fd962-IAD'), (b'etag', b'W/"296-6rfYDnkdzDkq/n4gCcDjJFn4z6k"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:11:54.448Z'), (b'x-api-call-start', b'2025-09-22T19:11:54.041Z'), (b'x-api-received', b'2025-09-22T19:11:54.033Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'197'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'xsuZJUH_bqKejo7KxNXWf9XJ80fLmf1R-yxX7SvRBGEfxzMGgNStjQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:11:54 GMT', 'x-ratelimit-remaining-tokens': '29165', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfHAQ-62bZhn-98341c5a5c6fd962', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341c5a5c6fd962-IAD', 'etag': 'W/"296-6rfYDnkdzDkq/n4gCcDjJFn4z6k"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:11:54.448Z', 'x-api-call-start': '2025-09-22T19:11:54.041Z', 'x-api-received': '2025-09-22T19:11:54.033Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '197', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'xsuZJUH_bqKejo7KxNXWf9XJ80fLmf1R-yxX7SvRBGEfxzMGgNStjQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfHAQ-62bZhn-98341c5a5c6fd962
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Pollution stats at -33.9249, 18.4241.' took 0.67s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': -33.9249, 'lon': 18.4241})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-62b0813c-eb8a-46d3-855f-294143112b74', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI now 35.6895, 139.6917.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:00 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfJqx-3NKUce-98341c7de8b6868a'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341c7de8b6868a-IAD'), (b'etag', b'W/"297-v4zPd3UUrB0Z7+GfSJk/ltwllcw"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:00.111Z'), (b'x-api-call-start', b'2025-09-22T19:11:59.704Z'), (b'x-api-received', b'2025-09-22T19:11:59.692Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'gLOGZl9tojR3Wz7l6azJG6x7vHh3rv3905iay-PLZ8qYCfBhaoG_pQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:00 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfJqx-3NKUce-98341c7de8b6868a', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341c7de8b6868a-IAD', 'etag': 'W/"297-v4zPd3UUrB0Z7+GfSJk/ltwllcw"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:00.111Z', 'x-api-call-start': '2025-09-22T19:11:59.704Z', 'x-api-received': '2025-09-22T19:11:59.692Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'gLOGZl9tojR3Wz7l6azJG6x7vHh3rv3905iay-PLZ8qYCfBhaoG_pQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfJqx-3NKUce-98341c7de8b6868a
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI now 35.6895, 139.6917.' took 0.70s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 139.6917, 'lon': -35.6895})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-aac9db1b-e3bb-4d4b-b8c9-c36f91e23466', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality 38.7223, -9.1393.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:05 GMT'), (b'x-ratelimit-remaining-tokens', b'28925'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfLZD-62bZhn-98341ca19f8fc98c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341ca19f8fc98c-IAD'), (b'etag', b'W/"295-fu4unzpM9VWBa+UKTXpzxnSigWk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:05.950Z'), (b'x-api-call-start', b'2025-09-22T19:12:05.456Z'), (b'x-api-received', b'2025-09-22T19:12:05.448Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'cIxa_JFW7VGHZ0TBJOTsIMOqEwTP2ZkCXZb525quuT_8eYUOejgYHQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:05 GMT', 'x-ratelimit-remaining-tokens': '28925', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfLZD-62bZhn-98341ca19f8fc98c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341ca19f8fc98c-IAD', 'etag': 'W/"295-fu4unzpM9VWBa+UKTXpzxnSigWk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:05.950Z', 'x-api-call-start': '2025-09-22T19:12:05.456Z', 'x-api-received': '2025-09-22T19:12:05.448Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b2401c931c3af269d92a4d6452b284c6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'cIxa_JFW7VGHZ0TBJOTsIMOqEwTP2ZkCXZb525quuT_8eYUOejgYHQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfLZD-62bZhn-98341ca19f8fc98c
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality 38.7223, -9.1393.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'lat': 38.7223, 'lon': -9.1393})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-4e0b63ad-5818-4ff7-8b6f-2cb47757254f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality for 10001, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D9774AF0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D97746D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:11 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfNKa-3NKUce-98341cc62a535707'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341cc62a535707-IAD'), (b'etag', b'W/"29e-rbV6kBLo0+4xFRA2uodZLzUZSwQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:11.832Z'), (b'x-api-call-start', b'2025-09-22T19:12:11.398Z'), (b'x-api-received', b'2025-09-22T19:12:11.385Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e5b7b0e902e41c76700f539e8964f7b2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'sDkp-zJXuUTGxdBxaJreuCqAG5kArSYWOKgZwGrCfDAbL58Bm9yvVg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:11 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfNKa-3NKUce-98341cc62a535707', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341cc62a535707-IAD', 'etag': 'W/"29e-rbV6kBLo0+4xFRA2uodZLzUZSwQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:11.832Z', 'x-api-call-start': '2025-09-22T19:12:11.398Z', 'x-api-received': '2025-09-22T19:12:11.385Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e5b7b0e902e41c76700f539e8964f7b2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'sDkp-zJXuUTGxdBxaJreuCqAG5kArSYWOKgZwGrCfDAbL58Bm9yvVg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfNKa-3NKUce-98341cc62a535707
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality for 10001, US.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '10001', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2769e79e-7e42-47f2-9f26-29592f762fe1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI now at 90210, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D9776860>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D9776440>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:17 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfQ4Z-3NKUce-98341ceb1e11d6db'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341ceb1e11d6db-IAD'), (b'etag', b'W/"29f-sy8hJUFy7V0RmTNm5HwftJE7XVQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:17.657Z'), (b'x-api-call-start', b'2025-09-22T19:12:17.260Z'), (b'x-api-received', b'2025-09-22T19:12:17.243Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ee8bf999ce540257d0864f3352ba5f18.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'JTnMzHEO240OAgBnpTpGxOJYu46aggteoJEGMPn37THMy--QGVHdyw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:17 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfQ4Z-3NKUce-98341ceb1e11d6db', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341ceb1e11d6db-IAD', 'etag': 'W/"29f-sy8hJUFy7V0RmTNm5HwftJE7XVQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:17.657Z', 'x-api-call-start': '2025-09-22T19:12:17.260Z', 'x-api-received': '2025-09-22T19:12:17.243Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ee8bf999ce540257d0864f3352ba5f18.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'JTnMzHEO240OAgBnpTpGxOJYu46aggteoJEGMPn37THMy--QGVHdyw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfQ4Z-3NKUce-98341ceb1e11d6db
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI now at 90210, US.' took 1.08s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '90210', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ddc2f731-31f4-4503-9c0a-8bc2c8e681e7', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Pollution level 60614, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D978C610>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D978C1F0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:23 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfRrf-62bZhn-98341d110dac0132'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341d110dac0132-IAD'), (b'etag', b'W/"2a0-IwaDU8ACj1MfHvqKofLR3zah9sM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:23.728Z'), (b'x-api-call-start', b'2025-09-22T19:12:23.288Z'), (b'x-api-received', b'2025-09-22T19:12:23.280Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f66c1bfd882cc1a8c6bff90fcf5c78e0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'XA7QmPpA5s4RamTHO2t-cguIlU9jpOgjcr93EN7cnrCIY5yDusEGSw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:23 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfRrf-62bZhn-98341d110dac0132', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341d110dac0132-IAD', 'etag': 'W/"2a0-IwaDU8ACj1MfHvqKofLR3zah9sM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:23.728Z', 'x-api-call-start': '2025-09-22T19:12:23.288Z', 'x-api-received': '2025-09-22T19:12:23.280Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f66c1bfd882cc1a8c6bff90fcf5c78e0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'XA7QmPpA5s4RamTHO2t-cguIlU9jpOgjcr93EN7cnrCIY5yDusEGSw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfRrf-62bZhn-98341d110dac0132
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Pollution level 60614, US.' took 0.89s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': '60614', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ca1e715d-d3fa-4a55-8163-0d8ffc31bbb2', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI 10115, DE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D9774460>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D9774DF0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:29 GMT'), (b'x-ratelimit-remaining-tokens', b'33137'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfTbW-62bZhn-98341d35aaab9393'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341d35aaab9393-IAD'), (b'etag', b'W/"29f-ueli5Wp2PKo7MA1QeV9XIk7pMQU"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:29.602Z'), (b'x-api-call-start', b'2025-09-22T19:12:29.137Z'), (b'x-api-received', b'2025-09-22T19:12:29.129Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'198'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 a4ab7d5e0c5f8a7089b039ed156b8ba2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'iNshO0-niMJP6BrcFsjhKRE_Maoxc1QeyWDtrT49TnW2Q5t2P4aKSw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:29 GMT', 'x-ratelimit-remaining-tokens': '33137', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfTbW-62bZhn-98341d35aaab9393', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341d35aaab9393-IAD', 'etag': 'W/"29f-ueli5Wp2PKo7MA1QeV9XIk7pMQU"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:29.602Z', 'x-api-call-start': '2025-09-22T19:12:29.137Z', 'x-api-received': '2025-09-22T19:12:29.129Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '198', 'x-cache': 'Miss from cloudfront', 'via': '1.1 a4ab7d5e0c5f8a7089b039ed156b8ba2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'iNshO0-niMJP6BrcFsjhKRE_Maoxc1QeyWDtrT49TnW2Q5t2P4aKSw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfTbW-62bZhn-98341d35aaab9393
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI 10115, DE.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '10115', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0bd5c4a6-add1-4094-b12e-139886ed6440', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality SW1A 1AA, GB.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D978C8B0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D878CCD0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:35 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfVLu-66dFFu-98341d5a5f3e061a'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341d5a5f3e061a-IAD'), (b'etag', b'W/"2a1-LA0z/uJkbxgrYo0VoWn3Wdwtkm4"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:35.449Z'), (b'x-api-call-start', b'2025-09-22T19:12:35.020Z'), (b'x-api-received', b'2025-09-22T19:12:35.010Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'uvodF9ryhC8bicoBsZpafLX9nv5_1fhOqqyDDsmTSyfw_44xbeEjGg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:35 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfVLu-66dFFu-98341d5a5f3e061a', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341d5a5f3e061a-IAD', 'etag': 'W/"2a1-LA0z/uJkbxgrYo0VoWn3Wdwtkm4"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:35.449Z', 'x-api-call-start': '2025-09-22T19:12:35.020Z', 'x-api-received': '2025-09-22T19:12:35.010Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'uvodF9ryhC8bicoBsZpafLX9nv5_1fhOqqyDDsmTSyfw_44xbeEjGg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfVLu-66dFFu-98341d5a5f3e061a
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality SW1A 1AA, GB.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': 'SW1A 1AA', 'country_code': 'GB'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-069190cf-a799-4ccc-a1f2-837a31054d5e', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI 75001, FR.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:41 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfX5a-66dFFu-98341d7e4ba8595b'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341d7e4ba8595b-IAD'), (b'etag', b'W/"29e-yGCgpZ41pjBRYQJGbi4aUIMfJno"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:41.351Z'), (b'x-api-call-start', b'2025-09-22T19:12:40.860Z'), (b'x-api-received', b'2025-09-22T19:12:40.850Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'e1AKUeiGz3AaG9Zwttd8xXREwoyZ2Ku4KjGvt3GqlSZaRQo4ZgYftA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:41 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfX5a-66dFFu-98341d7e4ba8595b', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341d7e4ba8595b-IAD', 'etag': 'W/"29e-yGCgpZ41pjBRYQJGbi4aUIMfJno"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:41.351Z', 'x-api-call-start': '2025-09-22T19:12:40.860Z', 'x-api-received': '2025-09-22T19:12:40.850Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2afdb7947d4ee2ad8275c94857985058.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'e1AKUeiGz3AaG9Zwttd8xXREwoyZ2Ku4KjGvt3GqlSZaRQo4ZgYftA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfX5a-66dFFu-98341d7e4ba8595b
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI 75001, FR.' took 0.86s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '75001', 'country_code': 'FR'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-66d27dfa-0a4d-4369-8bdd-e1cecdf78e4f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality 1250-096, PT.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D97A87F0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D97A83D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:47 GMT'), (b'x-ratelimit-remaining-tokens', b'25020'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfYrs-3NKUce-98341da32b7588d0'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341da32b7588d0-IAD'), (b'etag', b'W/"2af-b3C7gEnayZ07ws6N7kvr3mAJZgI"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:47.341Z'), (b'x-api-call-start', b'2025-09-22T19:12:46.851Z'), (b'x-api-received', b'2025-09-22T19:12:46.840Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 cccc9229643ffd588520c959b9b6ab16.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'uOrDzXZHOm_If2Pv62ltdOG4IkTysTlcRXFIfvrYmz3zUMzHZRyS0g==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:47 GMT', 'x-ratelimit-remaining-tokens': '25020', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfYrs-3NKUce-98341da32b7588d0', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341da32b7588d0-IAD', 'etag': 'W/"2af-b3C7gEnayZ07ws6N7kvr3mAJZgI"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:47.341Z', 'x-api-call-start': '2025-09-22T19:12:46.851Z', 'x-api-received': '2025-09-22T19:12:46.840Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 cccc9229643ffd588520c959b9b6ab16.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'uOrDzXZHOm_If2Pv62ltdOG4IkTysTlcRXFIfvrYmz3zUMzHZRyS0g=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfYrs-3NKUce-98341da32b7588d0
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality 1250-096, PT.' took 0.91s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '1250-096', 'country_code': 'PT'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2aa55dbf-3d8a-4bd3-86ac-7f0c3506f1ff', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI 2000, AU.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:52 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfaaV-3NKUce-98341dc7fdda57be'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341dc7fdda57be-IAD'), (b'etag', b'W/"2a9-mDrCmDbB77RuxSOphqJd+S9ElYE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:53.041Z'), (b'x-api-call-start', b'2025-09-22T19:12:52.629Z'), (b'x-api-received', b'2025-09-22T19:12:52.618Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 cccc9229643ffd588520c959b9b6ab16.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'SHHspAIjtVAvH9kxbUQJ3UtrNJfIp1dHdqjhtEiXgd1DVTdygWwDjQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:52 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfaaV-3NKUce-98341dc7fdda57be', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341dc7fdda57be-IAD', 'etag': 'W/"2a9-mDrCmDbB77RuxSOphqJd+S9ElYE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:53.041Z', 'x-api-call-start': '2025-09-22T19:12:52.629Z', 'x-api-received': '2025-09-22T19:12:52.618Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 cccc9229643ffd588520c959b9b6ab16.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'SHHspAIjtVAvH9kxbUQJ3UtrNJfIp1dHdqjhtEiXgd1DVTdygWwDjQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfaaV-3NKUce-98341dc7fdda57be
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI 2000, AU.' took 0.69s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'AU', 'country_code': 'AU'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fee16947-a81f-4fc9-a724-4eec8b18ce46', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality 01000-000, BR.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D97764A0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x00000225D7DA3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000225D97758D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:12:58 GMT'), (b'x-ratelimit-remaining-tokens', b'24415'), (b'x-ratelimit-reset', b'0'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfcGR-62bZhn-98341debfa1f390e'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341debfa1f390e-IAD'), (b'etag', b'W/"2af-Mm9Kw/WuV8lMBT3xk66mTGlk0es"'), (b'retry-after', b'0'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:12:58.752Z'), (b'x-api-call-start', b'2025-09-22T19:12:58.306Z'), (b'x-api-received', b'2025-09-22T19:12:58.298Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'198'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'-w4lP1qirqHhs5CODxSzddVmsc4aPQ_pbcVPXF4R8185S-yqNZr4Kg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:12:58 GMT', 'x-ratelimit-remaining-tokens': '24415', 'x-ratelimit-reset': '0', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfcGR-62bZhn-98341debfa1f390e', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341debfa1f390e-IAD', 'etag': 'W/"2af-Mm9Kw/WuV8lMBT3xk66mTGlk0es"', 'retry-after': '0', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:12:58.752Z', 'x-api-call-start': '2025-09-22T19:12:58.306Z', 'x-api-received': '2025-09-22T19:12:58.298Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '198', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': '-w4lP1qirqHhs5CODxSzddVmsc4aPQ_pbcVPXF4R8185S-yqNZr4Kg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfcGR-62bZhn-98341debfa1f390e
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality 01000-000, BR.' took 0.88s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '01000-000', 'country_code': 'BR'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-19648be4-b75a-4729-8c6e-1408530768f1', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI 110001, IN.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:13:04 GMT'), (b'x-ratelimit-remaining-tokens', b'28672'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHfdzf-62bZhn-98341e103cf8586e'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341e103cf8586e-IAD'), (b'etag', b'W/"2c3-bMii3KM1KrbpmawuoXIKviF0uPk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:13:04.595Z'), (b'x-api-call-start', b'2025-09-22T19:13:04.121Z'), (b'x-api-received', b'2025-09-22T19:13:04.112Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'TbrbjNe8EXn89nLc3m2lcOlFFJhlW4GoqWpTwLHGyWIrAM2hAUcMjQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:13:04 GMT', 'x-ratelimit-remaining-tokens': '28672', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHfdzf-62bZhn-98341e103cf8586e', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341e103cf8586e-IAD', 'etag': 'W/"2c3-bMii3KM1KrbpmawuoXIKviF0uPk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:13:04.595Z', 'x-api-call-start': '2025-09-22T19:13:04.121Z', 'x-api-received': '2025-09-22T19:13:04.112Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'TbrbjNe8EXn89nLc3m2lcOlFFJhlW4GoqWpTwLHGyWIrAM2hAUcMjQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHfdzf-62bZhn-98341e103cf8586e
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI 110001, IN.' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'IN', 'zip': '110001', 'country_code': 'IN'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-91d275cd-52c0-4e46-9a31-46dc0600ab13', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current AQI Kyoto, JP.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:13:10 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHffii-66dFFu-98341e349f6750e2'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98341e349f6750e2-IAD'), (b'etag', b'W/"2ac-KPiGWc6bMq4cPBXyodtM1ZUD1Vo"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:13:10.446Z'), (b'x-api-call-start', b'2025-09-22T19:13:09.925Z'), (b'x-api-received', b'2025-09-22T19:13:09.915Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MAD53-P3'), (b'X-Amz-Cf-Id', b'Gr1Cf4nbHgeDkS5hPslwfWRwWD6S9HF8eUg4TjLJA8sQrGH_4pfDCA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:13:10 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHffii-66dFFu-98341e349f6750e2', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98341e349f6750e2-IAD', 'etag': 'W/"2ac-KPiGWc6bMq4cPBXyodtM1ZUD1Vo"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:13:10.446Z', 'x-api-call-start': '2025-09-22T19:13:09.925Z', 'x-api-received': '2025-09-22T19:13:09.915Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ce236e3f354fc6ee23520308783c1392.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MAD53-P3', 'x-amz-cf-id': 'Gr1Cf4nbHgeDkS5hPslwfWRwWD6S9HF8eUg4TjLJA8sQrGH_4pfDCA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHffii-66dFFu-98341e349f6750e2
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Current AQI Kyoto, JP.' took 0.86s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Kyoto', 'country_code': 'JP'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-65c745d2-25f1-4e25-9254-67bde2042977', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality Toronto, CA now.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A1E3CD0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A1E3A00>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:01 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaD7B-62bZhn-9835187bdbf8d654'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835187bdbf8d654-IAD'), (b'etag', b'W/"2af-QWspz2cLRCb+bqDGsDDJJEpTPGM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:01.851Z'), (b'x-api-call-start', b'2025-09-22T22:04:01.337Z'), (b'x-api-received', b'2025-09-22T22:04:01.327Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2abb5f74a873ac896ca86a377e2601a6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'AoeQlmEWbUBxVB6RRXGYRDY-jnDSx_GORFke5KPX8TuT2FGwCxxLGg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:01 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaD7B-62bZhn-9835187bdbf8d654', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835187bdbf8d654-IAD', 'etag': 'W/"2af-QWspz2cLRCb+bqDGsDDJJEpTPGM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:01.851Z', 'x-api-call-start': '2025-09-22T22:04:01.337Z', 'x-api-received': '2025-09-22T22:04:01.327Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2abb5f74a873ac896ca86a377e2601a6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'AoeQlmEWbUBxVB6RRXGYRDY-jnDSx_GORFke5KPX8TuT2FGwCxxLGg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaD7B-62bZhn-9835187bdbf8d654
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality Toronto, CA now.' took 1.41s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Toronto', 'country_code': 'CA'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-1bedd639-340a-4965-8d2c-4a283083e277', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI Nairobi?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A225C30>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A2256C0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:07 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaEt4-66dFFu-983518a0b9e50818'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983518a0b9e50818-IAD'), (b'etag', b'W/"2a1-B+QlHX4NAMQiUGF7L29iVvO6WPI"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:07.759Z'), (b'x-api-call-start', b'2025-09-22T22:04:07.303Z'), (b'x-api-received', b'2025-09-22T22:04:07.293Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b3c9dae2f224efea0ff693ecfe19e9a0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'DAV9EUvU_wF9ge6OxuGKq8gN9H0fnPfVjRwOpL9JSZKeC1u5LyG51A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:07 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaEt4-66dFFu-983518a0b9e50818', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983518a0b9e50818-IAD', 'etag': 'W/"2a1-B+QlHX4NAMQiUGF7L29iVvO6WPI"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:07.759Z', 'x-api-call-start': '2025-09-22T22:04:07.303Z', 'x-api-received': '2025-09-22T22:04:07.293Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b3c9dae2f224efea0ff693ecfe19e9a0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'DAV9EUvU_wF9ge6OxuGKq8gN9H0fnPfVjRwOpL9JSZKeC1u5LyG51A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaEt4-66dFFu-983518a0b9e50818
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI Nairobi?' took 0.87s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Nairobi', 'country_code': 'KE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-53cf6cee-619e-4959-aa1d-8906ad13fb47', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality in Auckland, NZ.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:13 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaGfQ-3NKUce-983518c4de04e5e5'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983518c4de04e5e5-IAD'), (b'etag', b'W/"2af-+4Xf2M5u814D7hfSOE4gjqe+00o"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:13.717Z'), (b'x-api-call-start', b'2025-09-22T22:04:13.298Z'), (b'x-api-received', b'2025-09-22T22:04:13.288Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 b3c9dae2f224efea0ff693ecfe19e9a0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'vf0nvg6dog9H5jls-RU_AktPb75P_VVzPxRqSpuAoAjgoki9b26q9Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:13 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaGfQ-3NKUce-983518c4de04e5e5', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983518c4de04e5e5-IAD', 'etag': 'W/"2af-+4Xf2M5u814D7hfSOE4gjqe+00o"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:13.717Z', 'x-api-call-start': '2025-09-22T22:04:13.298Z', 'x-api-received': '2025-09-22T22:04:13.288Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 b3c9dae2f224efea0ff693ecfe19e9a0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'vf0nvg6dog9H5jls-RU_AktPb75P_VVzPxRqSpuAoAjgoki9b26q9Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaGfQ-3NKUce-983518c4de04e5e5
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality in Auckland, NZ.' took 0.72s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Auckland', 'country_code': 'NZ'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-8aa7e0a7-dc15-4af1-8033-62acb7e34fb5', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI Reykjavik, IS (sorry for prev typo).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A285450>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A285030>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:19 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaJTx-3NKUce-983518eadc893b2c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983518eadc893b2c-IAD'), (b'etag', b'W/"2a3-uauW4oB01A1ZeYYoq9vr8YNgPso"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:19.829Z'), (b'x-api-call-start', b'2025-09-22T22:04:19.362Z'), (b'x-api-received', b'2025-09-22T22:04:19.351Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 71e66581c6b0f838291d8c1c00c2a78a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'Pl4-pyPMEGN2ks_mHgh8hdM2ALsNUP01iM1L4aBpMVcQwRDbIiqcNQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:19 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaJTx-3NKUce-983518eadc893b2c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983518eadc893b2c-IAD', 'etag': 'W/"2a3-uauW4oB01A1ZeYYoq9vr8YNgPso"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:19.829Z', 'x-api-call-start': '2025-09-22T22:04:19.362Z', 'x-api-received': '2025-09-22T22:04:19.351Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 71e66581c6b0f838291d8c1c00c2a78a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'Pl4-pyPMEGN2ks_mHgh8hdM2ALsNUP01iM1L4aBpMVcQwRDbIiqcNQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaJTx-3NKUce-983518eadc893b2c
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI Reykjavik, IS (sorry for prev typo).' took 1.09s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Reykjavik', 'country_code': 'IS'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2dbcc147-b1dc-4f68-8cec-6808f5168e00', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Pollution level Lima, PE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A2871C0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A286DA0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:25 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaL7w-66dFFu-9835190f5a9a3ade'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835190f5a9a3ade-IAD'), (b'etag', b'W/"2ac-7wx4Rtn6S1BHC117JQsYappK+CQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:25.366Z'), (b'x-api-call-start', b'2025-09-22T22:04:24.929Z'), (b'x-api-received', b'2025-09-22T22:04:24.918Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2c03358c29f74a2113cb2bd8d036f480.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'NTv3BMDX_AwoM1eg_M4JC0hpyJY1IyGkdltNFfLZF_011PO2H02Iag==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:25 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaL7w-66dFFu-9835190f5a9a3ade', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835190f5a9a3ade-IAD', 'etag': 'W/"2ac-7wx4Rtn6S1BHC117JQsYappK+CQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:25.366Z', 'x-api-call-start': '2025-09-22T22:04:24.929Z', 'x-api-received': '2025-09-22T22:04:24.918Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2c03358c29f74a2113cb2bd8d036f480.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'NTv3BMDX_AwoM1eg_M4JC0hpyJY1IyGkdltNFfLZF_011PO2H02Iag=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaL7w-66dFFu-9835190f5a9a3ade
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Pollution level Lima, PE.' took 0.79s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Lima', 'country_code': 'PE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-de5e6a4d-ec54-45b1-9604-be5aa1c525bd', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI Johannesburg, ZA.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A2851B0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A284AC0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:31 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaMqs-66dFFu-98351933896805ec'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98351933896805ec-IAD'), (b'etag', b'W/"2c8-02uCV/z8YgcORSIfYiVvd2Zd4HM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:31.157Z'), (b'x-api-call-start', b'2025-09-22T22:04:30.726Z'), (b'x-api-received', b'2025-09-22T22:04:30.714Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f44a750f1ab6eb0f24a3374b498e11d0.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'yLX2i4LXDEMF0AMhGP1vQkF3zQMjOYs6sefsDzt0NvB8iXdGNT9pzw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:31 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaMqs-66dFFu-98351933896805ec', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98351933896805ec-IAD', 'etag': 'W/"2c8-02uCV/z8YgcORSIfYiVvd2Zd4HM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:31.157Z', 'x-api-call-start': '2025-09-22T22:04:30.726Z', 'x-api-received': '2025-09-22T22:04:30.714Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f44a750f1ab6eb0f24a3374b498e11d0.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'yLX2i4LXDEMF0AMhGP1vQkF3zQMjOYs6sefsDzt0NvB8iXdGNT9pzw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaMqs-66dFFu-98351933896805ec
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI Johannesburg, ZA.' took 0.77s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'zip': '', 'city': 'Johannesburg', 'country_code': 'ZA'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d0ce8443-4777-4b41-84ad-297dd8006c7c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality Munich, DE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A294790>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A294610>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:37 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaPe3-3NKUce-98351957bb39f508'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98351957bb39f508-IAD'), (b'etag', b'W/"2ac-89Rb4X/EYUGV7Y8MR0hrqXvni74"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:37.272Z'), (b'x-api-call-start', b'2025-09-22T22:04:36.768Z'), (b'x-api-received', b'2025-09-22T22:04:36.756Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ee49d7797f29b10f1d09e1b9d263b492.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'mLZ57uIP2s9pia_adYNC-sdf1JAa5YshrUhjTu_rHLOt61Wf6_4w6g==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:37 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaPe3-3NKUce-98351957bb39f508', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98351957bb39f508-IAD', 'etag': 'W/"2ac-89Rb4X/EYUGV7Y8MR0hrqXvni74"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:37.272Z', 'x-api-call-start': '2025-09-22T22:04:36.768Z', 'x-api-received': '2025-09-22T22:04:36.756Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ee49d7797f29b10f1d09e1b9d263b492.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'mLZ57uIP2s9pia_adYNC-sdf1JAa5YshrUhjTu_rHLOt61Wf6_4w6g=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaPe3-3NKUce-98351957bb39f508
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality Munich, DE.' took 0.85s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Munich', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-32b1cd7d-e25a-4864-8509-3f96562e1173', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'AQI San Francisco, US-CA.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A296500>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A2960E0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:42 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaRNo-3NKUce-9835197c3e42d6bf'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835197c3e42d6bf-IAD'), (b'etag', b'W/"2c0-yaSzASp+sr7yTwK/5+Ms/Qm4o/s"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:43.063Z'), (b'x-api-call-start', b'2025-09-22T22:04:42.611Z'), (b'x-api-received', b'2025-09-22T22:04:42.601Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2c03358c29f74a2113cb2bd8d036f480.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'WZMebhQIbsv1_yHd9Whx3Yq8A8Glc9GLBdLVjGro17c1VGDV8k_afw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:42 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaRNo-3NKUce-9835197c3e42d6bf', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835197c3e42d6bf-IAD', 'etag': 'W/"2c0-yaSzASp+sr7yTwK/5+Ms/Qm4o/s"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:43.063Z', 'x-api-call-start': '2025-09-22T22:04:42.611Z', 'x-api-received': '2025-09-22T22:04:42.601Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2c03358c29f74a2113cb2bd8d036f480.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': 'WZMebhQIbsv1_yHd9Whx3Yq8A8Glc9GLBdLVjGro17c1VGDV8k_afw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaRNo-3NKUce-9835197c3e42d6bf
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'AQI San Francisco, US-CA.' took 0.79s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'San Francisco', 'state_code': 'CA', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-04d2fdcf-5e72-43be-af1b-be89079205f4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Air quality Porto, PT.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A2B02B0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F9188EF7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F91A297E50>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 22:04:48 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJaT3K-66dFFu-983519a08fd123ad'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983519a08fd123ad-IAD'), (b'etag', b'W/"2ac-VUyCE5iOB4b0cE7UWAOWml5Ih78"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T22:04:48.635Z'), (b'x-api-call-start', b'2025-09-22T22:04:48.210Z'), (b'x-api-received', b'2025-09-22T22:04:48.198Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 74bc4d6da93c01db6e18e2b45fa9a18c.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'CDG54-P2'), (b'X-Amz-Cf-Id', b'2bRePvNwOpGZcVWbiCBR8A11jXO8fmLdMAKhGfKwD2bYoAA_-kZLFw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 22:04:48 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJaT3K-66dFFu-983519a08fd123ad', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983519a08fd123ad-IAD', 'etag': 'W/"2ac-VUyCE5iOB4b0cE7UWAOWml5Ih78"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T22:04:48.635Z', 'x-api-call-start': '2025-09-22T22:04:48.210Z', 'x-api-received': '2025-09-22T22:04:48.198Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 74bc4d6da93c01db6e18e2b45fa9a18c.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'CDG54-P2', 'x-amz-cf-id': '2bRePvNwOpGZcVWbiCBR8A11jXO8fmLdMAKhGfKwD2bYoAA_-kZLFw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJaT3K-66dFFu-983519a08fd123ad
DEBUG    test_performance:test_performance.py:319 Current air pollution conversation 'Air quality Porto, PT.' took 0.80s with response: 
LLMResponse(type='function_call', content=None, function='get_air_pollution', module='meteorology', arguments={'city': 'Porto', 'country_code': 'PT'})


