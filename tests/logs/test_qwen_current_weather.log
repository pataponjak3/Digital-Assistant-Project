DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-765a3664-7257-4e6a-a97b-b217109140dd', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current weather at 40.7128, -74.0060?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D988E3B80>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D988E38B0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 18:59:45 GMT'), (b'x-ratelimit-remaining-tokens', b'28412'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbYLp-62bZhn-98340a8b8d8f7f56'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340a8b8d8f7f56-IAD'), (b'etag', b'W/"297-bpE6ARUrzKeVerxaBJFIp+iHMQE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T18:59:45.145Z'), (b'x-api-call-start', b'2025-09-22T18:59:44.657Z'), (b'x-api-received', b'2025-09-22T18:59:44.650Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 9874b25ddff24dd18d4122c6a190ace4.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b't8HFUyI3yZhzOieYz7rOBQ5eEHpzCCyDo-qmavFW6hlilHA1P-4-2Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 18:59:45 GMT', 'x-ratelimit-remaining-tokens': '28412', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbYLp-62bZhn-98340a8b8d8f7f56', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340a8b8d8f7f56-IAD', 'etag': 'W/"297-bpE6ARUrzKeVerxaBJFIp+iHMQE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T18:59:45.145Z', 'x-api-call-start': '2025-09-22T18:59:44.657Z', 'x-api-received': '2025-09-22T18:59:44.650Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 9874b25ddff24dd18d4122c6a190ace4.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 't8HFUyI3yZhzOieYz7rOBQ5eEHpzCCyDo-qmavFW6hlilHA1P-4-2Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbYLp-62bZhn-98340a8b8d8f7f56
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current weather at 40.7128, -74.0060?' took 2.05s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 40.7128, 'lon': -74.006})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fcd18f0f-27ee-49d7-b570-a842152a6b02', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's it like now near -33.8688, 151.2093 (Sydny)?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98925AE0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98925570>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 18:59:51 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHba4H-3NKUce-98340ab0eea08199'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340ab0eea08199-IAD'), (b'etag', b'W/"2b2-T4J/7cnMv/1gE5wCNnqtQuUrLSQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T18:59:51.452Z'), (b'x-api-call-start', b'2025-09-22T18:59:50.429Z'), (b'x-api-received', b'2025-09-22T18:59:50.419Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3046b7404e796652c897921096103122.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'F9a03hZQKx0blDRFU-7HZTC0jyJAGvIuSydBsrpIq2G0BkR9ILWN8Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 18:59:51 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHba4H-3NKUce-98340ab0eea08199', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340ab0eea08199-IAD', 'etag': 'W/"2b2-T4J/7cnMv/1gE5wCNnqtQuUrLSQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T18:59:51.452Z', 'x-api-call-start': '2025-09-22T18:59:50.429Z', 'x-api-received': '2025-09-22T18:59:50.419Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3046b7404e796652c897921096103122.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'F9a03hZQKx0blDRFU-7HZTC0jyJAGvIuSydBsrpIq2G0BkR9ILWN8Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHba4H-3NKUce-98340ab0eea08199
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's it like now near -33.8688, 151.2093 (Sydny)?' took 1.53s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': -33.8688, 'lon': 151.2093, 'units': 'standart'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-98fdeeb4-1b4e-444f-8f5c-0f7afe03985b', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather rn at -23.5505, -46.6333.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98927970>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98927550>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 18:59:57 GMT'), (b'x-ratelimit-remaining-tokens', b'28005'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbc5Z-62bZhn-98340ad9e9ef399d'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340ad9e9ef399d-IAD'), (b'etag', b'W/"298-JCnqQNqIQdm6YA2AIqbcpaucdns"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T18:59:57.624Z'), (b'x-api-call-start', b'2025-09-22T18:59:57.230Z'), (b'x-api-received', b'2025-09-22T18:59:57.221Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'IeRL2fBAVG9DpqhLmgLqHMSY_DNwUEkFcVg66UeYj_Incb4QPujCbQ==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 18:59:57 GMT', 'x-ratelimit-remaining-tokens': '28005', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbc5Z-62bZhn-98340ad9e9ef399d', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340ad9e9ef399d-IAD', 'etag': 'W/"298-JCnqQNqIQdm6YA2AIqbcpaucdns"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T18:59:57.624Z', 'x-api-call-start': '2025-09-22T18:59:57.230Z', 'x-api-received': '2025-09-22T18:59:57.221Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'IeRL2fBAVG9DpqhLmgLqHMSY_DNwUEkFcVg66UeYj_Incb4QPujCbQ=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbc5Z-62bZhn-98340ad9e9ef399d
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather rn at -23.5505, -46.6333.' took 0.90s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': -23.5505, 'lon': -46.6333})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a62a7ea0-20e9-49f4-a577-c8ae963ff798', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Temp & conditions at 30.0444, 31.2357 please.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:03 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbdiy-3NKUce-98340afe1dcc9de2'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340afe1dcc9de2-IAD'), (b'etag', b'W/"2c2-I6BCRzDJeLm7uqPLabMnQt3cMGE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:03.344Z'), (b'x-api-call-start', b'2025-09-22T19:00:02.766Z'), (b'x-api-received', b'2025-09-22T19:00:02.754Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'7Z7YVjdGCwFGXb-kZhIls3g_Pp7WmjLv9nAL6duPlZL5DYuvBNsS7w==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:03 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbdiy-3NKUce-98340afe1dcc9de2', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340afe1dcc9de2-IAD', 'etag': 'W/"2c2-I6BCRzDJeLm7uqPLabMnQt3cMGE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:03.344Z', 'x-api-call-start': '2025-09-22T19:00:02.766Z', 'x-api-received': '2025-09-22T19:00:02.754Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': '7Z7YVjdGCwFGXb-kZhIls3g_Pp7WmjLv9nAL6duPlZL5DYuvBNsS7w=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbdiy-3NKUce-98340afe1dcc9de2
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Temp & conditions at 30.0444, 31.2357 please.' took 0.96s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 30.0444, 'lon': 31.2357, 'units': 'standart'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-61a7d0ae-42ac-4ba0-a5ea-30245289d179', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the current weather @ 55.7558, 37.6173?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:09 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbfZA-66dFFu-98340b234a894e62'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340b234a894e62-IAD'), (b'etag', b'W/"297-7wkMiXA+0vgyDbAT+iVJt3XyhBM"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:09.338Z'), (b'x-api-call-start', b'2025-09-22T19:00:08.925Z'), (b'x-api-received', b'2025-09-22T19:00:08.914Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'5cJRZPeRcySselaSW1WyqkXrrSmS3gjazLhLPQZOZLNjmdVRrgXc5A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:09 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbfZA-66dFFu-98340b234a894e62', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340b234a894e62-IAD', 'etag': 'W/"297-7wkMiXA+0vgyDbAT+iVJt3XyhBM"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:09.338Z', 'x-api-call-start': '2025-09-22T19:00:08.925Z', 'x-api-received': '2025-09-22T19:00:08.914Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': '5cJRZPeRcySselaSW1WyqkXrrSmS3gjazLhLPQZOZLNjmdVRrgXc5A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbfZA-66dFFu-98340b234a894e62
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's the current weather @ 55.7558, 37.6173?' took 0.74s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 55.7558, 'lon': 37.6173})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-cc6d310a-7e44-442d-8ab4-e46fe310ebef', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Is it raining around -1.2921, 36.8219 right now?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:15 GMT'), (b'x-ratelimit-remaining-tokens', b'27496'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbhGr-62bZhn-98340b476d3b3b7d'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340b476d3b3b7d-IAD'), (b'etag', b'W/"296-8NNG6EdeMrFk6jwHDrjhuEgOsDE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:15.176Z'), (b'x-api-call-start', b'2025-09-22T19:00:14.707Z'), (b'x-api-received', b'2025-09-22T19:00:14.696Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'oxXw5jpEfwV8Ny_OdcNNNCP2CLhyqUFoyimemLkLOEMuoPTemgXRsg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:15 GMT', 'x-ratelimit-remaining-tokens': '27496', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbhGr-62bZhn-98340b476d3b3b7d', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340b476d3b3b7d-IAD', 'etag': 'W/"296-8NNG6EdeMrFk6jwHDrjhuEgOsDE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:15.176Z', 'x-api-call-start': '2025-09-22T19:00:14.707Z', 'x-api-received': '2025-09-22T19:00:14.696Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3d4ac7efd2409b595925102be9dd340e.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'oxXw5jpEfwV8Ny_OdcNNNCP2CLhyqUFoyimemLkLOEMuoPTemgXRsg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbhGr-62bZhn-98340b476d3b3b7d
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Is it raining around -1.2921, 36.8219 right now?' took 0.79s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': -1.2921, 'lon': 36.8219})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-7b5b42d9-1775-420f-a1b9-d9de0c39224b', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'How cold is it near 64.1466, -21.9426?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98994BB0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D989949D0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:21 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbj3u-3NKUce-98340b6d3f63f276'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340b6d3f63f276-IAD'), (b'etag', b'W/"2c1-JC/ybuWrFVF9l/RBYaPjvhEfRvs"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:21.269Z'), (b'x-api-call-start', b'2025-09-22T19:00:20.681Z'), (b'x-api-received', b'2025-09-22T19:00:20.672Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 cd2eb52aa1d108faafa7c4de003507d2.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'sLLlxg9sOgFndD0JaOEtfsZ_hiCDYkcMwW2IT8defs8K8_ZpjcCtKw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:21 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbj3u-3NKUce-98340b6d3f63f276', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340b6d3f63f276-IAD', 'etag': 'W/"2c1-JC/ybuWrFVF9l/RBYaPjvhEfRvs"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:21.269Z', 'x-api-call-start': '2025-09-22T19:00:20.681Z', 'x-api-received': '2025-09-22T19:00:20.672Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 cd2eb52aa1d108faafa7c4de003507d2.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'sLLlxg9sOgFndD0JaOEtfsZ_hiCDYkcMwW2IT8defs8K8_ZpjcCtKw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbj3u-3NKUce-98340b6d3f63f276
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'How cold is it near 64.1466, -21.9426?' took 1.17s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 64.1466, 'lon': -21.9426, 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-a1541d7b-6dd5-4bde-bb14-e0d918f22fa8', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current wind & temp for -33.9249, 18.4241.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98996920>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98996500>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:27 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'1'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbkrZ-62bZhn-98340b92bf99d6d8'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340b92bf99d6d8-IAD'), (b'etag', b'W/"2a5-A03N7NSuj4bN8CozyGEkSMmki3U"'), (b'retry-after', b'1'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:27.290Z'), (b'x-api-call-start', b'2025-09-22T19:00:26.750Z'), (b'x-api-received', b'2025-09-22T19:00:26.743Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'198'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 3046b7404e796652c897921096103122.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'-r7MpDM_yiBSlmjVwExLXe21KWCk54JRssW5SjHgTMUjgfuX1HXo1w==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:27 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '1', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbkrZ-62bZhn-98340b92bf99d6d8', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340b92bf99d6d8-IAD', 'etag': 'W/"2a5-A03N7NSuj4bN8CozyGEkSMmki3U"', 'retry-after': '1', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:27.290Z', 'x-api-call-start': '2025-09-22T19:00:26.750Z', 'x-api-received': '2025-09-22T19:00:26.743Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '198', 'x-cache': 'Miss from cloudfront', 'via': '1.1 3046b7404e796652c897921096103122.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': '-r7MpDM_yiBSlmjVwExLXe21KWCk54JRssW5SjHgTMUjgfuX1HXo1w=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbkrZ-62bZhn-98340b92bf99d6d8
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current wind & temp for -33.9249, 18.4241.' took 1.04s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': -33.9249, 'lon': 18.4241})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-74685857-1e50-4a5c-aa73-4fe10f80208a', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather now at 35.6895, 139.6917 (Tokio)?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98996080>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D989963E0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:33 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbneR-66dFFu-98340bb86a04d6d8'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340bb86a04d6d8-IAD'), (b'etag', b'W/"297-mhghx7HVK+f6S/aeU7Cw2Iajdrk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:33.296Z'), (b'x-api-call-start', b'2025-09-22T19:00:32.777Z'), (b'x-api-received', b'2025-09-22T19:00:32.767Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 9907f51fb02da5e1928de8140598af14.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'ahCzahU2XQwVzsmHv8R8_MIeExQTjKTwacHVgMbOeBGwIp-28clJmA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:33 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbneR-66dFFu-98340bb86a04d6d8', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340bb86a04d6d8-IAD', 'etag': 'W/"297-mhghx7HVK+f6S/aeU7Cw2Iajdrk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:33.296Z', 'x-api-call-start': '2025-09-22T19:00:32.777Z', 'x-api-received': '2025-09-22T19:00:32.767Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 9907f51fb02da5e1928de8140598af14.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'ahCzahU2XQwVzsmHv8R8_MIeExQTjKTwacHVgMbOeBGwIp-28clJmA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbneR-66dFFu-98340bb86a04d6d8
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather now at 35.6895, 139.6917 (Tokio)?' took 0.92s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 35.6895, 'lon': 139.6917})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-08de7533-27ff-4c27-a2ce-c48e829a5c25', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the weather like at 38.7223, -9.1393?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98982B30>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98982A70>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:39 GMT'), (b'x-ratelimit-remaining-tokens', b'28707'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbpQk-62bZhn-98340bdd8d6b16de'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340bdd8d6b16de-IAD'), (b'etag', b'W/"2ad-EUsCFx/E9V5g3RiUOzGG3LaxWyE"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:39.592Z'), (b'x-api-call-start', b'2025-09-22T19:00:38.710Z'), (b'x-api-received', b'2025-09-22T19:00:38.701Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 feb24448bf4558d4eaf8be9cf460ac86.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'TumSx4Jy0yT-MhhZMvlXb_zL6DxQB2zr170LAIVUC_E1BrTG9HZyLg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:39 GMT', 'x-ratelimit-remaining-tokens': '28707', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbpQk-62bZhn-98340bdd8d6b16de', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340bdd8d6b16de-IAD', 'etag': 'W/"2ad-EUsCFx/E9V5g3RiUOzGG3LaxWyE"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:39.592Z', 'x-api-call-start': '2025-09-22T19:00:38.710Z', 'x-api-received': '2025-09-22T19:00:38.701Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 feb24448bf4558d4eaf8be9cf460ac86.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'TumSx4Jy0yT-MhhZMvlXb_zL6DxQB2zr170LAIVUC_E1BrTG9HZyLg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbpQk-62bZhn-98340bdd8d6b16de
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's the weather like at 38.7223, -9.1393?' took 1.35s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'lat': 38.7223, 'lon': -9.1393, 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-10df5003-6131-47c2-8c70-1b2491c6f067', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current weather for zip 10001, US.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:45 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbrHg-66dFFu-98340c04bf5e05e2'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340c04bf5e05e2-IAD'), (b'etag', b'W/"2a1-/t14IAaQU2TJXYHJcp2eV0g9Puk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:45.795Z'), (b'x-api-call-start', b'2025-09-22T19:00:45.029Z'), (b'x-api-received', b'2025-09-22T19:00:45.020Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 feb24448bf4558d4eaf8be9cf460ac86.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'4wSUsDwyVqlKpMKkATU8kaW0hs-5KK7wE5K_DsDY7s7XEf6vrjmsiA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:45 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbrHg-66dFFu-98340c04bf5e05e2', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340c04bf5e05e2-IAD', 'etag': 'W/"2a1-/t14IAaQU2TJXYHJcp2eV0g9Puk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:45.795Z', 'x-api-call-start': '2025-09-22T19:00:45.029Z', 'x-api-received': '2025-09-22T19:00:45.020Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 feb24448bf4558d4eaf8be9cf460ac86.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': '4wSUsDwyVqlKpMKkATU8kaW0hs-5KK7wE5K_DsDY7s7XEf6vrjmsiA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbrHg-66dFFu-98340c04bf5e05e2
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current weather for zip 10001, US.' took 1.10s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '10001', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-0c97b14a-2334-44fb-b36a-a29474874137', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather now at 90210, US?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997DD50>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997D930>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:51 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbt97-66dFFu-98340c2bcd092d1e'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340c2bcd092d1e-IAD'), (b'etag', b'W/"2a0-P8cMVuRsh1MqelndBt5yL2u0hxo"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:51.849Z'), (b'x-api-call-start', b'2025-09-22T19:00:51.261Z'), (b'x-api-received', b'2025-09-22T19:00:51.251Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 62a32701712a1c992cbde6a244acac8c.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'oD786HLI7rJHxsBNe8l76bwDwBngPQWcqgCqt0JdxztVkjIXE0CiIw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:51 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbt97-66dFFu-98340c2bcd092d1e', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340c2bcd092d1e-IAD', 'etag': 'W/"2a0-P8cMVuRsh1MqelndBt5yL2u0hxo"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:51.849Z', 'x-api-call-start': '2025-09-22T19:00:51.261Z', 'x-api-received': '2025-09-22T19:00:51.251Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 62a32701712a1c992cbde6a244acac8c.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'oD786HLI7rJHxsBNe8l76bwDwBngPQWcqgCqt0JdxztVkjIXE0CiIw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbt97-66dFFu-98340c2bcd092d1e
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather now at 90210, US?' took 1.17s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '90210', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fab8a0ee-3491-47d4-9b4e-8a43499567ff', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "How's Chicago right now—60614, US."}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997FAC0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997F6A0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:00:58 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbuxb-66dFFu-98340c51fc74c9a0'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340c51fc74c9a0-IAD'), (b'etag', b'W/"2a0-2G0moNbUmNBZBOGKq9p6NzaMay4"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:00:57.895Z'), (b'x-api-call-start', b'2025-09-22T19:00:57.378Z'), (b'x-api-received', b'2025-09-22T19:00:57.368Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 bd3f8a07a0dda8b80498a0b92378cd90.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'RBoA9qtcCbmpTuRsPljEnjnXULnk5CKffJuWmh3P_djFOASyJ5Gb5A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:00:58 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbuxb-66dFFu-98340c51fc74c9a0', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340c51fc74c9a0-IAD', 'etag': 'W/"2a0-2G0moNbUmNBZBOGKq9p6NzaMay4"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:00:57.895Z', 'x-api-call-start': '2025-09-22T19:00:57.378Z', 'x-api-received': '2025-09-22T19:00:57.368Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 bd3f8a07a0dda8b80498a0b92378cd90.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'RBoA9qtcCbmpTuRsPljEnjnXULnk5CKffJuWmh3P_djFOASyJ5Gb5A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbuxb-66dFFu-98340c51fc74c9a0
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'How's Chicago right now—60614, US.' took 1.37s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '60614', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-9e6f167f-f6a9-4041-9e02-63137ed7be55', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's it like at 10115, DE (Berlin)?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98927D00>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98927610>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:04 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbwuk-3NKUce-98340c7a2b251771'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340c7a2b251771-IAD'), (b'etag', b'W/"2a1-skE3AwE6SUZ+/g31cZroH3VuTcA"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:04.420Z'), (b'x-api-call-start', b'2025-09-22T19:01:03.941Z'), (b'x-api-received', b'2025-09-22T19:01:03.931Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 f6d06657c3cf81ebd927805f386acb54.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'KwwB6nSlTzDTpbONpQV65Y2xfLCkiYMRpM3Q0wAdw31V3hmhtoLNVg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:04 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbwuk-3NKUce-98340c7a2b251771', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340c7a2b251771-IAD', 'etag': 'W/"2a1-skE3AwE6SUZ+/g31cZroH3VuTcA"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:04.420Z', 'x-api-call-start': '2025-09-22T19:01:03.941Z', 'x-api-received': '2025-09-22T19:01:03.931Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 f6d06657c3cf81ebd927805f386acb54.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'KwwB6nSlTzDTpbONpQV65Y2xfLCkiYMRpM3Q0wAdw31V3hmhtoLNVg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbwuk-3NKUce-98340c7a2b251771
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's it like at 10115, DE (Berlin)?' took 1.00s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '10115', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2f9a314a-ba3b-478d-92b4-2cf1a0462335', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather for SW1A 1AA, GB (Buckingham)?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997D7B0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997F160>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:10 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHbyeE-62bZhn-98340c9f8efec98c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340c9f8efec98c-IAD'), (b'etag', b'W/"2e5-2KU0etArBzNYJblonvNBqd6rbH8"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:10.328Z'), (b'x-api-call-start', b'2025-09-22T19:01:09.768Z'), (b'x-api-received', b'2025-09-22T19:01:09.759Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 ab0b1e7cbd7487a4d0b7fa6622ab2758.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'7sitK5Bd92pqHy_Ae0wRcJGFDsN0Hpp-fIMKC5mYI5Cn-DsIU0KtDA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:10 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHbyeE-62bZhn-98340c9f8efec98c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340c9f8efec98c-IAD', 'etag': 'W/"2e5-2KU0etArBzNYJblonvNBqd6rbH8"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:10.328Z', 'x-api-call-start': '2025-09-22T19:01:09.768Z', 'x-api-received': '2025-09-22T19:01:09.759Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 ab0b1e7cbd7487a4d0b7fa6622ab2758.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': '7sitK5Bd92pqHy_Ae0wRcJGFDsN0Hpp-fIMKC5mYI5Cn-DsIU0KtDA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHbyeE-62bZhn-98340c9f8efec98c
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather for SW1A 1AA, GB (Buckingham)?' took 0.95s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': 'SW1A 1AA', 'country_code': 'GB', 'units': 'standart', 'lang': 'en'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-3a55feaf-13b2-47ae-a460-7f3499b05ac9', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Now in 75001, FR?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98996200>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D989941F0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:16 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHc1R3-62bZhn-98340cc4c93497a6'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340cc4c93497a6-IAD'), (b'etag', b'W/"2a1-u2GVetyDk7BnkB25nzCTPJHbm8w"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:16.164Z'), (b'x-api-call-start', b'2025-09-22T19:01:15.731Z'), (b'x-api-received', b'2025-09-22T19:01:15.723Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'p_IKJ_1SToJ0bg_29kCSi0tj9-Hsd4z-o3Ci88RqUdMUU5IIDcZIvw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:16 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHc1R3-62bZhn-98340cc4c93497a6', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340cc4c93497a6-IAD', 'etag': 'W/"2a1-u2GVetyDk7BnkB25nzCTPJHbm8w"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:16.164Z', 'x-api-call-start': '2025-09-22T19:01:15.731Z', 'x-api-received': '2025-09-22T19:01:15.723Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'p_IKJ_1SToJ0bg_29kCSi0tj9-Hsd4z-o3Ci88RqUdMUU5IIDcZIvw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHc1R3-62bZhn-98340cc4c93497a6
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Now in 75001, FR?' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '75001', 'country_code': 'FR'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-30c92ad5-13a0-4318-8c25-72d70c49fb97', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current weather for 1250-096, PT (Lisboa)?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:21 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHc37f-3NKUce-98340ce93e80c573'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340ce93e80c573-IAD'), (b'etag', b'W/"2bb-R60z+QdZ2SKjzLoDQYsMQOOAUGU"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:21.866Z'), (b'x-api-call-start', b'2025-09-22T19:01:21.455Z'), (b'x-api-received', b'2025-09-22T19:01:21.442Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'n9JeAlam9qoeo0FBzCEuyAqSXYbt98bLl52p2BnyuKBQLLYWUFKn-Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:21 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHc37f-3NKUce-98340ce93e80c573', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340ce93e80c573-IAD', 'etag': 'W/"2bb-R60z+QdZ2SKjzLoDQYsMQOOAUGU"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:21.866Z', 'x-api-call-start': '2025-09-22T19:01:21.455Z', 'x-api-received': '2025-09-22T19:01:21.442Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'n9JeAlam9qoeo0FBzCEuyAqSXYbt98bLl52p2BnyuKBQLLYWUFKn-Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHc37f-3NKUce-98340ce93e80c573
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current weather for 1250-096, PT (Lisboa)?' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '1250-096', 'country_code': 'PT', 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-db8b5f7a-a325-4ee6-a3cb-d9057172fb84', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's it now at 2000, AU (Sydney CBD)?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D999BCA30>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D999BC610>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:28 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHc4rT-3NKUce-98340d0e2fb3ed75'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340d0e2fb3ed75-IAD'), (b'etag', b'W/"2e5-tlNQFHl9YMHITdxM8qMVfs+jQg4"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:27.834Z'), (b'x-api-call-start', b'2025-09-22T19:01:27.298Z'), (b'x-api-received', b'2025-09-22T19:01:27.288Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2be9be209fae0745dbb221e90c68aafa.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'A6Kk0XNHc_hQg0rW0KyuJ50xa1ciEegNQfACNViY0JTT-yCc-3eMXw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:28 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHc4rT-3NKUce-98340d0e2fb3ed75', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340d0e2fb3ed75-IAD', 'etag': 'W/"2e5-tlNQFHl9YMHITdxM8qMVfs+jQg4"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:27.834Z', 'x-api-call-start': '2025-09-22T19:01:27.298Z', 'x-api-received': '2025-09-22T19:01:27.288Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2be9be209fae0745dbb221e90c68aafa.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'A6Kk0XNHc_hQg0rW0KyuJ50xa1ciEegNQfACNViY0JTT-yCc-3eMXw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHc4rT-3NKUce-98340d0e2fb3ed75
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's it now at 2000, AU (Sydney CBD)?' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Sydney', 'country_code': 'AU', 'units': 'standart', 'lang': 'en'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-80c266a6-dfbf-47d9-80fa-043f791d14cf', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather rn at 01000-000, BR (São Paulo).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:33 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHc6bD-3NKUce-98340d32bcbdc946'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340d32bcbdc946-IAD'), (b'etag', b'W/"2bc-ThDku4zttwWrXO5x2xVwNLc+6o0"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:33.720Z'), (b'x-api-call-start', b'2025-09-22T19:01:33.142Z'), (b'x-api-received', b'2025-09-22T19:01:33.133Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 2be9be209fae0745dbb221e90c68aafa.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'xG79u-70_M-L4G1QIPZy9Z9DAYISgWQiBMhUEgnSPa7qaaHrV1IU1Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:33 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHc6bD-3NKUce-98340d32bcbdc946', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340d32bcbdc946-IAD', 'etag': 'W/"2bc-ThDku4zttwWrXO5x2xVwNLc+6o0"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:33.720Z', 'x-api-call-start': '2025-09-22T19:01:33.142Z', 'x-api-received': '2025-09-22T19:01:33.133Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 2be9be209fae0745dbb221e90c68aafa.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'xG79u-70_M-L4G1QIPZy9Z9DAYISgWQiBMhUEgnSPa7qaaHrV1IU1Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHc6bD-3NKUce-98340d32bcbdc946
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather rn at 01000-000, BR (São Paulo).' took 0.94s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '01000-000', 'country_code': 'BR', 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-f136a484-4680-4b8c-9dbd-1e6672499858', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current conditions for 110001, IN (New Delhi).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997FE20>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9997F610>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:39 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHc8Ua-62bZhn-98340d59395381a6'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340d59395381a6-IAD'), (b'etag', b'W/"2b9-pmcwhSFls5N43hP9vnJKTXGj2d0"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:39.890Z'), (b'x-api-call-start', b'2025-09-22T19:01:39.483Z'), (b'x-api-received', b'2025-09-22T19:01:39.475Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'b5MOM-gTsZPGmM9AORfCSIQJpLRNdFT4WYBRVJtnPRrJNm7R9kg4Tg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:39 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHc8Ua-62bZhn-98340d59395381a6', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340d59395381a6-IAD', 'etag': 'W/"2b9-pmcwhSFls5N43hP9vnJKTXGj2d0"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:39.890Z', 'x-api-call-start': '2025-09-22T19:01:39.483Z', 'x-api-received': '2025-09-22T19:01:39.475Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 0d7deb275c6269c1898f9fac0cd690b6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'b5MOM-gTsZPGmM9AORfCSIQJpLRNdFT4WYBRVJtnPRrJNm7R9kg4Tg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHc8Ua-62bZhn-98340d59395381a6
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current conditions for 110001, IN (New Delhi).' took 0.93s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'zip': '110001', 'country_code': 'IN', 'units': 'metric'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-482138fd-648d-4c67-b589-0995301c544f', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the weather in Kyoto, JP right now?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D98927D60>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000024D97FB3D40> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000024D9999D330>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:45 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHcAFM-66dFFu-98340d7dbf27c566'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340d7dbf27c566-IAD'), (b'etag', b'W/"2a2-Gkc5Sb5ETLLTG8GvAnjZLvxF6Fs"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:45.895Z'), (b'x-api-call-start', b'2025-09-22T19:01:45.447Z'), (b'x-api-received', b'2025-09-22T19:01:45.436Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e5b482ce8b5bb64cfe4de1d81504c0b6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'tB4CF3rHUrVdnR1JRjglRGUQvA6W-xRMRodx0hTwJgVxshlw1fRf5A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:45 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHcAFM-66dFFu-98340d7dbf27c566', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340d7dbf27c566-IAD', 'etag': 'W/"2a2-Gkc5Sb5ETLLTG8GvAnjZLvxF6Fs"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:45.895Z', 'x-api-call-start': '2025-09-22T19:01:45.447Z', 'x-api-received': '2025-09-22T19:01:45.436Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e5b482ce8b5bb64cfe4de1d81504c0b6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'tB4CF3rHUrVdnR1JRjglRGUQvA6W-xRMRodx0hTwJgVxshlw1fRf5A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHcAFM-66dFFu-98340d7dbf27c566
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's the weather in Kyoto, JP right now?' took 0.99s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Kyoto', 'country_code': 'JP'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2780cde4-e4c7-4b1f-b9fc-5bbeaa939911', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current conditions in Toronto, CA?'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 19:01:52 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCHcC1L-66dFFu-98340da33946c9a1'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'98340da33946c9a1-IAD'), (b'etag', b'W/"2bc-kY2eo+sVQSJIQILovBXGE1pxG5U"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T19:01:52.111Z'), (b'x-api-call-start', b'2025-09-22T19:01:51.362Z'), (b'x-api-received', b'2025-09-22T19:01:51.351Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e5b482ce8b5bb64cfe4de1d81504c0b6.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'MRS52-P3'), (b'X-Amz-Cf-Id', b'sp4q3mNlWSyqyFTCBxy7qrIL-cLtmcBQ67EvqmCj1J_f1s1flnmv7Q==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 19:01:52 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCHcC1L-66dFFu-98340da33946c9a1', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '98340da33946c9a1-IAD', 'etag': 'W/"2bc-kY2eo+sVQSJIQILovBXGE1pxG5U"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T19:01:52.111Z', 'x-api-call-start': '2025-09-22T19:01:51.362Z', 'x-api-received': '2025-09-22T19:01:51.351Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e5b482ce8b5bb64cfe4de1d81504c0b6.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'MRS52-P3', 'x-amz-cf-id': 'sp4q3mNlWSyqyFTCBxy7qrIL-cLtmcBQ67EvqmCj1J_f1s1flnmv7Q=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCHcC1L-66dFFu-98340da33946c9a1
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current conditions in Toronto, CA?' took 1.18s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Toronto', 'country_code': 'CA', 'units': 'imperial'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-63382635-c562-4215-9265-6084c189c3c7', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "How's Nairobi today?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3A83C10>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3A83940>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:22 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVhrW-3NKUce-983503071b7a081a'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983503071b7a081a-IAD'), (b'etag', b'W/"28a-+Cq+x1fyIk66U2xh0Yf9B292ONc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:22.870Z'), (b'x-api-call-start', b'2025-09-22T21:49:22.483Z'), (b'x-api-received', b'2025-09-22T21:49:22.471Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 dd1211d51ecc66d1523e03934a660f3a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'c0-5x62qT5UZ1QEYu2qFv2ftPzWd5D11pq1dkcew2Bgv_M_AOiADtA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:22 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVhrW-3NKUce-983503071b7a081a', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983503071b7a081a-IAD', 'etag': 'W/"28a-+Cq+x1fyIk66U2xh0Yf9B292ONc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:22.870Z', 'x-api-call-start': '2025-09-22T21:49:22.483Z', 'x-api-received': '2025-09-22T21:49:22.471Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 dd1211d51ecc66d1523e03934a660f3a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'c0-5x62qT5UZ1QEYu2qFv2ftPzWd5D11pq1dkcew2Bgv_M_AOiADtA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVhrW-3NKUce-983503071b7a081a
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'How's Nairobi today?' took 1.28s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Nairobi'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-96057cb3-b32b-4f2a-8a7c-f90f86aa14c4', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather now in Auckland, NZ.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3ACDB70>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3ACD600>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:28 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVjb3-66dFFu-9835032b19d7d6cd'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835032b19d7d6cd-IAD'), (b'etag', b'W/"2a5-DYOVAXKIAE5XL872wHPH9YrJfqQ"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:28.723Z'), (b'x-api-call-start', b'2025-09-22T21:49:28.312Z'), (b'x-api-received', b'2025-09-22T21:49:28.302Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 a3ef506c047603361a1618325060e832.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'RIH8vzamLs3Z_EnLkJId2acbt1rXAUUPAMeiR5JX7x51VS_3qnie6w==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:28 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVjb3-66dFFu-9835032b19d7d6cd', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835032b19d7d6cd-IAD', 'etag': 'W/"2a5-DYOVAXKIAE5XL872wHPH9YrJfqQ"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:28.723Z', 'x-api-call-start': '2025-09-22T21:49:28.312Z', 'x-api-received': '2025-09-22T21:49:28.302Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 a3ef506c047603361a1618325060e832.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'RIH8vzamLs3Z_EnLkJId2acbt1rXAUUPAMeiR5JX7x51VS_3qnie6w=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVjb3-66dFFu-9835032b19d7d6cd
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather now in Auckland, NZ.' took 0.80s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Auckland', 'country_code': 'NZ'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-85019cbd-c90b-453d-88aa-b346d9cba46d', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's it like in Reykyavik, IS?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3ACFA00>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3ACF5E0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:34 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVmJv-66dFFu-9835034f7be7d634'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835034f7be7d634-IAD'), (b'etag', b'W/"2a6-S5Gb69zPv64OljHhPmCFsKoiPZk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:34.558Z'), (b'x-api-call-start', b'2025-09-22T21:49:34.106Z'), (b'x-api-received', b'2025-09-22T21:49:34.095Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 4939467e567a49e735e944a78fc9ac32.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'bwctDOGJ8OTyA4U6GGgkuJSrap4jlyKe5qGRwOHEOiWsPp1YYKsygA==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:34 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVmJv-66dFFu-9835034f7be7d634', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835034f7be7d634-IAD', 'etag': 'W/"2a6-S5Gb69zPv64OljHhPmCFsKoiPZk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:34.558Z', 'x-api-call-start': '2025-09-22T21:49:34.106Z', 'x-api-received': '2025-09-22T21:49:34.095Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 4939467e567a49e735e944a78fc9ac32.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'bwctDOGJ8OTyA4U6GGgkuJSrap4jlyKe5qGRwOHEOiWsPp1YYKsygA=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVmJv-66dFFu-9835034f7be7d634
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's it like in Reykyavik, IS?' took 0.82s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Reykyavik', 'country_code': 'IS'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-559cf5bd-9dc3-4e32-bc35-e9652494772c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current weather for Lima, PE.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:40 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVo33-66dFFu-983503735e16066c'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983503735e16066c-IAD'), (b'etag', b'W/"2a1-E46sx+HutxTbgwRHGIZD/SsWKPU"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:40.312Z'), (b'x-api-call-start', b'2025-09-22T21:49:39.915Z'), (b'x-api-received', b'2025-09-22T21:49:39.902Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 4939467e567a49e735e944a78fc9ac32.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'0EYGmuZinZ-kgLy7c3jQBPqTO6Gv2L_udkPyYETXI6y6hVC3QLNF2g==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:40 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVo33-66dFFu-983503735e16066c', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983503735e16066c-IAD', 'etag': 'W/"2a1-E46sx+HutxTbgwRHGIZD/SsWKPU"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:40.312Z', 'x-api-call-start': '2025-09-22T21:49:39.915Z', 'x-api-received': '2025-09-22T21:49:39.902Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 4939467e567a49e735e944a78fc9ac32.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': '0EYGmuZinZ-kgLy7c3jQBPqTO6Gv2L_udkPyYETXI6y6hVC3QLNF2g=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVo33-66dFFu-983503735e16066c
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current weather for Lima, PE.' took 0.77s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Lima', 'country_code': 'PE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-2a1056f2-f350-45c8-a946-15b0a0fe1afd', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "How's Jo'burg (Johannesburg, ZA) right now?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3B27100>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3B26CE0>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:46 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVpkk-66dFFu-9835039828689db4'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'9835039828689db4-IAD'), (b'etag', b'W/"2a8-lKdd0DZLbmdqUIznccFG8zdH4sc"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:46.154Z'), (b'x-api-call-start', b'2025-09-22T21:49:45.695Z'), (b'x-api-received', b'2025-09-22T21:49:45.685Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 e07486e51a3aad165a6bab2a951bba48.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'rcc64xV43vF_XGWfXW9D7cSs28qJfYbZm7bkSyooQMKhdY5Tkqs4jw==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:46 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVpkk-66dFFu-9835039828689db4', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '9835039828689db4-IAD', 'etag': 'W/"2a8-lKdd0DZLbmdqUIznccFG8zdH4sc"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:46.154Z', 'x-api-call-start': '2025-09-22T21:49:45.695Z', 'x-api-received': '2025-09-22T21:49:45.685Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 e07486e51a3aad165a6bab2a951bba48.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'rcc64xV43vF_XGWfXW9D7cSs28qJfYbZm7bkSyooQMKhdY5Tkqs4jw=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVpkk-66dFFu-9835039828689db4
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'How's Jo'burg (Johannesburg, ZA) right now?' took 0.79s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Johannesburg', 'country_code': 'ZA'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-26013e4c-1d45-4038-a3a4-81f98653309e', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Weather in Munich, DE (now).'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3ACF340>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3B25330>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:51 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVrTs-3NKUce-983503bc781c8238'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983503bc781c8238-IAD'), (b'etag', b'W/"2a2-nxpNmSWKmOG/ZjMQJIMs/RrUUQk"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:51.821Z'), (b'x-api-call-start', b'2025-09-22T21:49:51.445Z'), (b'x-api-received', b'2025-09-22T21:49:51.434Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 d387fec28536c5aa92926c56363afe9a.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'-hoVynTYjdN4LwPxvQrtu6x1-ng2ullRHNIKFZUc1J-QOf8SUYrL_A==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:51 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVrTs-3NKUce-983503bc781c8238', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983503bc781c8238-IAD', 'etag': 'W/"2a2-nxpNmSWKmOG/ZjMQJIMs/RrUUQk"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:51.821Z', 'x-api-call-start': '2025-09-22T21:49:51.445Z', 'x-api-received': '2025-09-22T21:49:51.434Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 d387fec28536c5aa92926c56363afe9a.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': '-hoVynTYjdN4LwPxvQrtu6x1-ng2ullRHNIKFZUc1J-QOf8SUYrL_A=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVrTs-3NKUce-983503bc781c8238
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Weather in Munich, DE (now).' took 0.76s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Munich', 'country_code': 'DE'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-c8437c4c-7957-486d-bb68-0ec19d4536f6', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': 'Current conditions San Francisco, US-CA.'}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.connection:_trace.py:47 close.started
DEBUG    httpcore.connection:_trace.py:47 close.complete
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.started host='router.huggingface.co' port=443 local_address=None timeout=5.0 socket_options=None
DEBUG    httpcore.connection:_trace.py:47 connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3B346D0>
DEBUG    httpcore.connection:_trace.py:47 start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021DD315F7C0> server_hostname='router.huggingface.co' timeout=5.0
DEBUG    httpcore.connection:_trace.py:47 start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021DD3B34550>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:49:57 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVtCX-3NKUce-983503e08fc1d6e9'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983503e08fc1d6e9-IAD'), (b'etag', b'W/"2c2-DNawggoisvE5LPqZk/5Ewr4Fiwg"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:49:57.687Z'), (b'x-api-call-start', b'2025-09-22T21:49:57.285Z'), (b'x-api-received', b'2025-09-22T21:49:57.273Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 88e066f06ce21d9d589e0b7dba0cd180.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'aXixMDSWIY9-6vNQMiEriijsiMEom7RQnLM8Q0ZPjVmozrPaNZ8nlg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:49:57 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVtCX-3NKUce-983503e08fc1d6e9', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983503e08fc1d6e9-IAD', 'etag': 'W/"2c2-DNawggoisvE5LPqZk/5Ewr4Fiwg"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:49:57.687Z', 'x-api-call-start': '2025-09-22T21:49:57.285Z', 'x-api-received': '2025-09-22T21:49:57.273Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 88e066f06ce21d9d589e0b7dba0cd180.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'aXixMDSWIY9-6vNQMiEriijsiMEom7RQnLM8Q0ZPjVmozrPaNZ8nlg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVtCX-3NKUce-983503e08fc1d6e9
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'Current conditions San Francisco, US-CA.' took 0.79s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'San Francisco', 'state_code': 'CA', 'country_code': 'US'})


DEBUG    openai._base_client:_base_client.py:482 Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-ffaa5f45-9cea-41ca-95da-2d52e99e6f7c', 'json_data': {'messages': [{'role': 'system', 'content': 'You are a digital assistant that can call predefined functions when they match the user\'s request.\n\nIMPORTANT RULES:\n- If the user’s input matches a function, reply ONLY with a JSON object in this format:\n{\n  "module": "<module_name>",\n  "function": "<function_name>",\n  "arguments": { "key": "value" }\n}\nDo not include explanations, disclaimers, or any other text.\n- If the user’s input does NOT match a function, reply naturally.\n\nAvailable functions:\n\nFunction: get_current_weather\nModule: meteorology\nDescription: Get the current weather for a location.\nArguments:\n- city (string): City name. Optionally add state_code (only for USA) and country_code (follows ISO 3166).\n- lat (number) and lon (number): Coordinates (-90 to 90, -180 to 180).\n- zip (string) and country_code (string): Postal code and country code.\n- units (string): Optional. Temperature unit: standart, metric, imperial.\n- lang (string): Optional. Language code for weather description (e.g., \'en\').\n\nFunction: get_forecast\nModule: meteorology\nDescription: Get a 5-day forecast in 3-hour intervals.\nArguments: Same as get_current_weather.\n\nFunction: get_air_pollution\nModule: meteorology\nDescription: Get current air pollution data for a location.\nArguments: Same as get_current_weather.\n\nFunction: launch_application\nModule: os\nDescription: Launches an application by its name in the system, if it has a shortcut in the Start Menu.\nArguments:\n- app_name (string): The name of the application to launch.\n- is_sure_after_multiple_matches (bool): Indicates if the user confirmed which application to launch when multiple matches were found before in the conversation.\n\n\nOnly respond with a JSON object when the user’s message clearly requires calling a function (like requesting weather or pollution data). For example, "What’s the weather in Lisbon?" would match a function.\n\nIf the user refers to earlier data or asks follow-up questions about information you already returned (e.g., “What can you tell me about this data?”), answer NATURALLY and DO NOT generate a JSON object.\n\nNever reflect on how you should have responded unless told otherwise. Focus on answering the user’s latest question or request clearly and helpfully, using the information you already provided if relevant.'}, {'role': 'user', 'content': "What's the weather in Porto, PT?"}], 'model': 'Qwen/Qwen2.5-7B-Instruct', 'temperature': 0.7, 'tool_choice': None, 'tools': None, 'top_p': 0.9}}
DEBUG    openai._base_client:_base_client.py:978 Sending HTTP Request: POST https://router.huggingface.co/v1/chat/completions
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_headers.complete
DEBUG    httpcore.http11:_trace.py:47 send_request_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 send_request_body.complete
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Date', b'Mon, 22 Sep 2025 21:50:03 GMT'), (b'x-ratelimit-remaining-tokens', b'33333'), (b'x-ratelimit-reset', b'2'), (b'X-Powered-By', b'huggingface-moon'), (b'vary', b'Accept-Encoding'), (b'access-control-allow-origin', b'*'), (b'Access-Control-Expose-Headers', b'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash'), (b'X-Robots-Tag', b'none'), (b'cross-origin-opener-policy', b'same-origin'), (b'Referrer-Policy', b'strict-origin-when-cross-origin'), (b'x-request-id', b'oCJVur8-3NKUce-983504040b4c81e1'), (b'x-inference-provider', b'together'), (b'cf-cache-status', b'DYNAMIC'), (b'cf-ray', b'983504040b4c81e1-IAD'), (b'etag', b'W/"2a1-Niocub3J0y95ZGC15NH/npCw8K8"'), (b'retry-after', b'2'), (b'server', b'cloudflare'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains'), (b'x-api-call-end', b'2025-09-22T21:50:03.288Z'), (b'x-api-call-start', b'2025-09-22T21:50:02.829Z'), (b'x-api-received', b'2025-09-22T21:50:02.818Z'), (b'x-inference-version', b'v2'), (b'x-ratelimit', b'false'), (b'x-ratelimit-limit', b'100'), (b'x-ratelimit-limit-tokens', b'33333'), (b'x-ratelimit-remaining', b'199'), (b'X-Cache', b'Miss from cloudfront'), (b'Via', b'1.1 88e066f06ce21d9d589e0b7dba0cd180.cloudfront.net (CloudFront)'), (b'X-Amz-Cf-Pop', b'LHR50-P8'), (b'X-Amz-Cf-Id', b'yjkyx7u0vQEdtWrRJSdN3LyuiOJCj5ZsvPNDUi-hmC9zm6BxE066Mg==')])
INFO     httpx:_client.py:1025 HTTP Request: POST https://router.huggingface.co/v1/chat/completions "HTTP/1.1 200 OK"
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.started request=<Request [b'POST']>
DEBUG    httpcore.http11:_trace.py:47 receive_response_body.complete
DEBUG    httpcore.http11:_trace.py:47 response_closed.started
DEBUG    httpcore.http11:_trace.py:47 response_closed.complete
DEBUG    openai._base_client:_base_client.py:1016 HTTP Response: POST https://router.huggingface.co/v1/chat/completions "200 OK" Headers({'content-type': 'application/json; charset=utf-8', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'date': 'Mon, 22 Sep 2025 21:50:03 GMT', 'x-ratelimit-remaining-tokens': '33333', 'x-ratelimit-reset': '2', 'x-powered-by': 'huggingface-moon', 'vary': 'Accept-Encoding', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Repo-Commit,X-Request-Id,X-Error-Code,X-Error-Message,X-Total-Count,ETag,Link,Accept-Ranges,Content-Range,X-Linked-Size,X-Linked-ETag,X-Xet-Hash', 'x-robots-tag': 'none', 'cross-origin-opener-policy': 'same-origin', 'referrer-policy': 'strict-origin-when-cross-origin', 'x-request-id': 'oCJVur8-3NKUce-983504040b4c81e1', 'x-inference-provider': 'together', 'cf-cache-status': 'DYNAMIC', 'cf-ray': '983504040b4c81e1-IAD', 'etag': 'W/"2a1-Niocub3J0y95ZGC15NH/npCw8K8"', 'retry-after': '2', 'server': 'cloudflare', 'strict-transport-security': 'max-age=15552000; includeSubDomains', 'x-api-call-end': '2025-09-22T21:50:03.288Z', 'x-api-call-start': '2025-09-22T21:50:02.829Z', 'x-api-received': '2025-09-22T21:50:02.818Z', 'x-inference-version': 'v2', 'x-ratelimit': 'false', 'x-ratelimit-limit': '100', 'x-ratelimit-limit-tokens': '33333', 'x-ratelimit-remaining': '199', 'x-cache': 'Miss from cloudfront', 'via': '1.1 88e066f06ce21d9d589e0b7dba0cd180.cloudfront.net (CloudFront)', 'x-amz-cf-pop': 'LHR50-P8', 'x-amz-cf-id': 'yjkyx7u0vQEdtWrRJSdN3LyuiOJCj5ZsvPNDUi-hmC9zm6BxE066Mg=='})
DEBUG    openai._base_client:_base_client.py:1024 request_id: oCJVur8-3NKUce-983504040b4c81e1
DEBUG    test_performance:test_performance.py:292 Current weather conversation 'What's the weather in Porto, PT?' took 0.73s with response: 
LLMResponse(type='function_call', content=None, function='get_current_weather', module='meteorology', arguments={'city': 'Porto', 'country_code': 'PT'})


